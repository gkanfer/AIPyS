<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Tutorials &mdash; AIPyS  documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="AIPyS modules" href="API.html" />
    <link rel="prev" title="Installing AIPyS" href="install/index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> AIPyS
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="install/index.html">Installing AIPyS</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Tutorials</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#parametric-segmentation">1 Parametric Segmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#deep-learning-segmentation">2 Deep learning Segmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#naive-bayes-algorithm-granularity-classifier">3 Naive Bayes Algorithm-Granularity Classifier</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="API.html">AIPyS modules</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">AIPyS</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a></li>
      <li class="breadcrumb-item active">Tutorials</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/Tutorial.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="tutorials">
<h1>Tutorials<a class="headerlink" href="#tutorials" title="Permalink to this headline"></a></h1>
<section id="parametric-segmentation">
<h2>1 Parametric Segmentation<a class="headerlink" href="#parametric-segmentation" title="Permalink to this headline"></a></h2>
<p>The AIPS packdge provides two alternative methods for segmenting cells: parametric or deep-learning segmentation.
For parametric segmentation, we enhanced and translated our  <a class="reference external" href="https://www.r-project.org/">R</a>-based code.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">AIPyS</span> <span class="kn">import</span> <span class="n">AIPS_module</span> <span class="k">as</span> <span class="n">ai</span>
<span class="kn">from</span> <span class="nn">AIPyS</span> <span class="kn">import</span> <span class="n">AIPS_functions</span> <span class="k">as</span> <span class="n">af</span>
<span class="kn">from</span> <span class="nn">AIPyS</span> <span class="kn">import</span> <span class="n">AIPS_file_display</span> <span class="k">as</span> <span class="n">afd</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>F:\Gil\anaconda\envs\pm-tf24-cellpose\lib\site-packages\skimage\viewer\utils\__init__.py:1: UserWarning: Recommended matplotlib backend is `Agg` for full skimage.viewer functionality.
  from .core import *
</pre></div>
</div>
<p>We demonstrate the image segmentation of a capture of Catalase-GFP expressing u2os cells. This image was cropped from a 2044x2048 pixel image to a size of 512x512.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">io</span>
<span class="n">image_pex</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s1">&#39;catGFP.tif&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><img alt="png" src="_images/output_5_0_1.png" /></p>
<p>Set AIPyS object for preforming segmentation of the nucleus (seed),</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">AIPS_object</span> <span class="o">=</span> <span class="n">ai</span><span class="o">.</span><span class="n">Segmentation</span><span class="p">(</span><span class="n">Image_name</span><span class="o">=</span> <span class="s1">&#39;catGFP.tif&#39;</span><span class="p">,</span> <span class="n">path</span> <span class="o">=</span> <span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="n">ch_</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">rmv_object_nuc</span> <span class="o">=</span> <span class="mf">0.12</span><span class="p">,</span><span class="n">block_size</span> <span class="o">=</span> <span class="mi">59</span><span class="p">,</span> <span class="n">offset</span><span class="o">=-</span><span class="mi">4</span><span class="p">,</span> <span class="n">clean</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">seed</span> <span class="o">=</span> <span class="n">AIPS_object</span><span class="o">.</span><span class="n">seedSegmentation</span><span class="p">()</span>
<span class="n">nmask2</span> <span class="o">=</span> <span class="n">seed</span><span class="p">[</span><span class="s1">&#39;nmask2&#39;</span><span class="p">]</span> <span class="c1">#Local threshold map - seed</span>
<span class="n">sort_mask</span> <span class="o">=</span> <span class="n">seed</span><span class="p">[</span><span class="s1">&#39;sort_mask&#39;</span><span class="p">]</span> <span class="c1">#RGB map - seed</span>
</pre></div>
</div>
<p>Then object is used for segmenting based on the nucleus as a seed.
where the seed  segmentation parametrs are pluged in.
Calculate a threshold mask image by using a weighted mean (block_size) of the local neighborhood of each pixel, minus a offset.</p>
<p><img alt="png" src="_images/output_7_0_1.png" /></p>
<p>Target channel (Catalase-GFP) was used to identify cell borders and edges for segmentation. High-pass filtering, local thresholding, and global thresholding were then used to create global and local masks.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">target</span> <span class="o">=</span> <span class="n">AIPS_object</span><span class="o">.</span><span class="n">cytosolSegmentation</span><span class="p">(</span><span class="n">ch2_</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">block_size_cyto</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">offset_cyto</span><span class="o">=-</span><span class="mi">5</span><span class="p">,</span> <span class="n">global_ther</span><span class="o">=</span> <span class="mf">0.51</span><span class="p">,</span> <span class="n">rmv_object_cyto</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">rmv_object_cyto_small</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>
<span class="n">combine</span> <span class="o">=</span> <span class="n">target</span><span class="p">[</span><span class="s1">&#39;combine&#39;</span><span class="p">]</span>
<span class="n">cseg_mask</span> <span class="o">=</span> <span class="n">target</span><span class="p">[</span><span class="s1">&#39;cseg_mask&#39;</span><span class="p">]</span>
<span class="n">mask_unfiltered</span> <span class="o">=</span> <span class="n">target</span><span class="p">[</span><span class="s1">&#39;mask_unfiltered&#39;</span><span class="p">]</span>
<span class="n">maskContour</span> <span class="o">=</span> <span class="n">afd</span><span class="o">.</span><span class="n">Compsite_display</span><span class="p">(</span><span class="n">input_image</span> <span class="o">=</span> <span class="n">image_pex</span><span class="p">[</span><span class="mi">0</span><span class="p">,:,:],</span> <span class="n">mask_roi</span> <span class="o">=</span> <span class="n">cseg_mask</span><span class="p">,</span> <span class="n">channel</span><span class="o">=</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">draw_ROI_contour</span><span class="p">()</span>
</pre></div>
</div>
<p><img alt="png" src="_images/output_9_0_1.png" /></p>
</section>
<section id="deep-learning-segmentation">
<h2>2 Deep learning Segmentation<a class="headerlink" href="#deep-learning-segmentation" title="Permalink to this headline"></a></h2>
<p>The CellPose method (publish by Stinger et. al. ) uses a neural network (NN) to detect and segment cells from an input image. The NN is trained on a dataset of labeled images, with the labels indicating which pixels belong to each cell. After training, the network is able to accurately identify cells in a new image. CellPose also allows for the detection of multiple cells in an image, allowing for the analysis of cell colonies.</p>
<p>In conclusion, the CellPose method provides an efficient and accurate way to segment cells from microscopy images. This method can be used to analyze individual cells or cell colonies, allowing for the accurate measurement of cell features.</p>
<ul class="simple">
<li><p>Stringer, C., Wang, T., Michaelos, M., &amp; Pachitariu, M. (2021). Cellpose: a generalist algorithm for cellular segmentation. <em>Nature methods, 18</em>(1), 100-106.
[<a class="reference external" href="https://scholar.googleusercontent.com/scholar.bib?q=info:rmoKTp0cEiYJ:scholar.google.com/&amp;output=citation&amp;scisdr=CgXHFLYtEMb9qOfkmrg:AAGBfm0AAAAAY2jigrhA_p9qteLfyKDZlh96dZdapgkX&amp;scisig=AAGBfm0AAAAAY2jigv55oXhgKwSArS2sr_fxBh--42gU&amp;scisf=4&amp;ct=citation&amp;cd=-1&amp;hl=en&amp;scfhb=1">bibtex</a>] <Br></p></li>
<li><p><a class="reference external" href="https://github.com/MouseLand/cellpose">Cellpose github page</a></p></li>
</ul>
<p>We integrated Cellpose with the AIPS platform to enable automatic capture of cell borders.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">AIPyS</span> <span class="kn">import</span> <span class="n">AIPS_cellpose</span> <span class="k">as</span> <span class="n">AC</span>
</pre></div>
</div>
<p>In addation, the compsite_display module for display the mask contour</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">AIPyS</span> <span class="kn">import</span> <span class="n">AIPS_file_display</span> <span class="k">as</span> <span class="n">afd</span>
</pre></div>
</div>
<p>Similar to the parametric segmentation method, GFP-expressing Catalase images are uploaded and analyzed using the <code class="docutils literal notranslate"><span class="pre">AIPS_cellpose</span></code> module.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">AIPS_pose_object</span> <span class="o">=</span> <span class="n">AC</span><span class="o">.</span><span class="n">AIPS_cellpose</span><span class="p">(</span><span class="n">Image_name</span> <span class="o">=</span> <span class="s1">&#39;catGFP.tif&#39;</span><span class="p">,</span> <span class="n">path</span> <span class="o">=</span> <span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="n">model_type</span> <span class="o">=</span> <span class="s1">&#39;cyto&#39;</span><span class="p">,</span> <span class="n">channels</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">AIPS_pose_object</span><span class="o">.</span><span class="n">cellpose_image_load</span><span class="p">()</span>
</pre></div>
</div>
<p>The parameter <code class="docutils literal notranslate"><span class="pre">channels=[0,0]</span></code> indicates input grayscale image.</p>
<p>The module <code class="docutils literal notranslate"><span class="pre">cellpose_segmantation</span></code> calls for CellPose segmentation algorithm, and returns target mask (in this case “cyto”) and features table.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mask</span><span class="p">,</span> <span class="n">table</span> <span class="o">=</span> <span class="n">AIPS_pose_object</span><span class="o">.</span><span class="n">cellpose_segmantation</span><span class="p">(</span><span class="n">image_input</span><span class="o">=</span><span class="n">img</span><span class="p">[</span><span class="mi">0</span><span class="p">,:,:])</span>
</pre></div>
</div>
<p>Display cytosolic mask contour using the <code class="docutils literal notranslate"><span class="pre">Compsite_display</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">maskContour</span> <span class="o">=</span> <span class="n">afd</span><span class="o">.</span><span class="n">Compsite_display</span><span class="p">(</span><span class="n">input_image</span> <span class="o">=</span> <span class="n">img</span><span class="p">[</span><span class="mi">0</span><span class="p">,:,:],</span> <span class="n">mask_roi</span> <span class="o">=</span> <span class="n">mask</span><span class="p">,</span> <span class="n">channel</span><span class="o">=</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">draw_ROI_contour</span><span class="p">()</span>
</pre></div>
</div>
<p><img alt="png" src="_images/output_7_0_2.png" /></p>
</section>
<section id="naive-bayes-algorithm-granularity-classifier">
<h2>3 Naive Bayes Algorithm-Granularity Classifier<a class="headerlink" href="#naive-bayes-algorithm-granularity-classifier" title="Permalink to this headline"></a></h2>
<p>Naive Bayes Algorithm-Granularity Classifier</p>
<p>We will use AIPS platform to distinguish between peroxisome-positive and peroxisome-negative cells by imaging GFP-expressing Catalse. To model peroxisomes, we will use Pex13 mutant cells, with GFP-cat signal spread throughout the cytoplasm.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">AIPS_cellpose</span></code> module is used for segmenting input image cytoplasmic signal.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">AIPyS.AIPS_cellpose</span> <span class="kn">import</span> <span class="n">granularityMesure_cellpose</span>
</pre></div>
</div>
<p>Segment cells and measure area of each cell which is marked in red. In the cellular level, granularity will be analysed.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="n">wt</span><span class="p">,</span> <span class="n">WTtable</span><span class="p">,</span> <span class="n">WTdf</span> <span class="o">=</span> <span class="n">granularityMesure_cellpose</span><span class="p">(</span><span class="n">file</span> <span class="o">=</span> <span class="n">fileNmae</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">path</span> <span class="o">=</span> <span class="n">path</span><span class="p">,</span> <span class="n">classLabel</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
                               <span class="n">outPath</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">clean</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">outputTableName</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span><span class="n">saveMode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">intensity</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">kO</span><span class="p">,</span> <span class="n">kOtable</span><span class="p">,</span> <span class="n">kOdf</span> <span class="o">=</span> <span class="n">granularityMesure_cellpose</span><span class="p">(</span><span class="n">file</span> <span class="o">=</span> <span class="n">fileNmae</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">path</span> <span class="o">=</span> <span class="n">path</span><span class="p">,</span> <span class="n">classLabel</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
                               <span class="n">outPath</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">clean</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">outputTableName</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span><span class="n">saveMode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">intensity</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">wt</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">gray</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="s1">&#39;WT&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">ko</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">gray</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="s1">&#39;PEX3KO&#39;</span><span class="p">)</span>

</pre></div>
</div>
<p><img alt="png" src="_images/output_2_0_3.png" /></p>
<p>The method of analysis of granularity examines the effect of openings of increasing size on images of differing granularity. The volume of the open image is calculated as the sum of all pixels in each step, and the difference in volume between these successive steps is the granular spectrum. This granular spectrum is then normalized to the total volume (integrated intensity) of the image in order to create a diagram that displays how the different sizes of opening affect the images. Phenotype are assigned for training the model. For example, <strong>1</strong> for Pex3-KO and <strong>0</strong> for the WT cells. </Br>
Marge Granularity Table from both classes and plot Granularity spectrum.</p>
<style type="text/css">
#T_77728_ th {
  font-size: 8px;
  max-width: 50px;
}
#T_77728_ td {
  font-size: 8px;
  max-width: 50px;
}
</style>
<table id="T_77728_">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th class="col_heading level0 col0" >index</th>
      <th class="col_heading level0 col1" >kernel</th>
      <th class="col_heading level0 col2" >Signal intensity (ratio)</th>
      <th class="col_heading level0 col3" >classLabel</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_77728_level0_row0" class="row_heading level0 row0" >0</th>
      <td id="T_77728_row0_col0" class="data row0 col0" >0</td>
      <td id="T_77728_row0_col1" class="data row0 col1" >0</td>
      <td id="T_77728_row0_col2" class="data row0 col2" >1.000000</td>
      <td id="T_77728_row0_col3" class="data row0 col3" >0</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row1" class="row_heading level0 row1" >1</th>
      <td id="T_77728_row1_col0" class="data row1 col0" >1</td>
      <td id="T_77728_row1_col1" class="data row1 col1" >2</td>
      <td id="T_77728_row1_col2" class="data row1 col2" >0.890134</td>
      <td id="T_77728_row1_col3" class="data row1 col3" >0</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row2" class="row_heading level0 row2" >2</th>
      <td id="T_77728_row2_col0" class="data row2 col0" >2</td>
      <td id="T_77728_row2_col1" class="data row2 col1" >8</td>
      <td id="T_77728_row2_col2" class="data row2 col2" >0.656016</td>
      <td id="T_77728_row2_col3" class="data row2 col3" >0</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row3" class="row_heading level0 row3" >3</th>
      <td id="T_77728_row3_col0" class="data row3 col0" >3</td>
      <td id="T_77728_row3_col1" class="data row3 col1" >14</td>
      <td id="T_77728_row3_col2" class="data row3 col2" >0.513061</td>
      <td id="T_77728_row3_col3" class="data row3 col3" >0</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row4" class="row_heading level0 row4" >4</th>
      <td id="T_77728_row4_col0" class="data row4 col0" >4</td>
      <td id="T_77728_row4_col1" class="data row4 col1" >21</td>
      <td id="T_77728_row4_col2" class="data row4 col2" >0.381961</td>
      <td id="T_77728_row4_col3" class="data row4 col3" >0</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row5" class="row_heading level0 row5" >5</th>
      <td id="T_77728_row5_col0" class="data row5 col0" >5</td>
      <td id="T_77728_row5_col1" class="data row5 col1" >27</td>
      <td id="T_77728_row5_col2" class="data row5 col2" >0.282762</td>
      <td id="T_77728_row5_col3" class="data row5 col3" >0</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row6" class="row_heading level0 row6" >6</th>
      <td id="T_77728_row6_col0" class="data row6 col0" >6</td>
      <td id="T_77728_row6_col1" class="data row6 col1" >34</td>
      <td id="T_77728_row6_col2" class="data row6 col2" >0.221506</td>
      <td id="T_77728_row6_col3" class="data row6 col3" >0</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row7" class="row_heading level0 row7" >7</th>
      <td id="T_77728_row7_col0" class="data row7 col0" >7</td>
      <td id="T_77728_row7_col1" class="data row7 col1" >40</td>
      <td id="T_77728_row7_col2" class="data row7 col2" >0.190235</td>
      <td id="T_77728_row7_col3" class="data row7 col3" >0</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row8" class="row_heading level0 row8" >8</th>
      <td id="T_77728_row8_col0" class="data row8 col0" >8</td>
      <td id="T_77728_row8_col1" class="data row8 col1" >47</td>
      <td id="T_77728_row8_col2" class="data row8 col2" >0.157380</td>
      <td id="T_77728_row8_col3" class="data row8 col3" >0</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row9" class="row_heading level0 row9" >9</th>
      <td id="T_77728_row9_col0" class="data row9 col0" >9</td>
      <td id="T_77728_row9_col1" class="data row9 col1" >53</td>
      <td id="T_77728_row9_col2" class="data row9 col2" >0.139901</td>
      <td id="T_77728_row9_col3" class="data row9 col3" >0</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row10" class="row_heading level0 row10" >10</th>
      <td id="T_77728_row10_col0" class="data row10 col0" >10</td>
      <td id="T_77728_row10_col1" class="data row10 col1" >60</td>
      <td id="T_77728_row10_col2" class="data row10 col2" >0.127143</td>
      <td id="T_77728_row10_col3" class="data row10 col3" >0</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row11" class="row_heading level0 row11" >11</th>
      <td id="T_77728_row11_col0" class="data row11 col0" >0</td>
      <td id="T_77728_row11_col1" class="data row11 col1" >0</td>
      <td id="T_77728_row11_col2" class="data row11 col2" >1.000000</td>
      <td id="T_77728_row11_col3" class="data row11 col3" >1</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row12" class="row_heading level0 row12" >12</th>
      <td id="T_77728_row12_col0" class="data row12 col0" >1</td>
      <td id="T_77728_row12_col1" class="data row12 col1" >2</td>
      <td id="T_77728_row12_col2" class="data row12 col2" >0.951306</td>
      <td id="T_77728_row12_col3" class="data row12 col3" >1</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row13" class="row_heading level0 row13" >13</th>
      <td id="T_77728_row13_col0" class="data row13 col0" >2</td>
      <td id="T_77728_row13_col1" class="data row13 col1" >8</td>
      <td id="T_77728_row13_col2" class="data row13 col2" >0.848492</td>
      <td id="T_77728_row13_col3" class="data row13 col3" >1</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row14" class="row_heading level0 row14" >14</th>
      <td id="T_77728_row14_col0" class="data row14 col0" >3</td>
      <td id="T_77728_row14_col1" class="data row14 col1" >14</td>
      <td id="T_77728_row14_col2" class="data row14 col2" >0.732633</td>
      <td id="T_77728_row14_col3" class="data row14 col3" >1</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row15" class="row_heading level0 row15" >15</th>
      <td id="T_77728_row15_col0" class="data row15 col0" >4</td>
      <td id="T_77728_row15_col1" class="data row15 col1" >21</td>
      <td id="T_77728_row15_col2" class="data row15 col2" >0.637133</td>
      <td id="T_77728_row15_col3" class="data row15 col3" >1</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row16" class="row_heading level0 row16" >16</th>
      <td id="T_77728_row16_col0" class="data row16 col0" >5</td>
      <td id="T_77728_row16_col1" class="data row16 col1" >27</td>
      <td id="T_77728_row16_col2" class="data row16 col2" >0.482065</td>
      <td id="T_77728_row16_col3" class="data row16 col3" >1</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row17" class="row_heading level0 row17" >17</th>
      <td id="T_77728_row17_col0" class="data row17 col0" >6</td>
      <td id="T_77728_row17_col1" class="data row17 col1" >34</td>
      <td id="T_77728_row17_col2" class="data row17 col2" >0.363300</td>
      <td id="T_77728_row17_col3" class="data row17 col3" >1</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row18" class="row_heading level0 row18" >18</th>
      <td id="T_77728_row18_col0" class="data row18 col0" >7</td>
      <td id="T_77728_row18_col1" class="data row18 col1" >40</td>
      <td id="T_77728_row18_col2" class="data row18 col2" >0.292876</td>
      <td id="T_77728_row18_col3" class="data row18 col3" >1</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row19" class="row_heading level0 row19" >19</th>
      <td id="T_77728_row19_col0" class="data row19 col0" >8</td>
      <td id="T_77728_row19_col1" class="data row19 col1" >47</td>
      <td id="T_77728_row19_col2" class="data row19 col2" >0.254713</td>
      <td id="T_77728_row19_col3" class="data row19 col3" >1</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row20" class="row_heading level0 row20" >20</th>
      <td id="T_77728_row20_col0" class="data row20 col0" >9</td>
      <td id="T_77728_row20_col1" class="data row20 col1" >53</td>
      <td id="T_77728_row20_col2" class="data row20 col2" >0.240333</td>
      <td id="T_77728_row20_col3" class="data row20 col3" >1</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row21" class="row_heading level0 row21" >21</th>
      <td id="T_77728_row21_col0" class="data row21 col0" >10</td>
      <td id="T_77728_row21_col1" class="data row21 col1" >60</td>
      <td id="T_77728_row21_col2" class="data row21 col2" >0.232534</td>
      <td id="T_77728_row21_col3" class="data row21 col3" >1</td>
    </tr>
  </tbody>
</table>
<p>Merging the granularity tables and ploting granularity spectrom over time:
<code class="docutils literal notranslate"><span class="pre">python</span>&#160;&#160;&#160;&#160; <span class="pre">GranPerCell</span> <span class="pre">=</span> <span class="pre">pd.concat((WTgTable,kOgTable))</span>&#160;&#160;&#160;&#160; </code></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.lines.Line2D at 0x1e217f56488&gt;
</pre></div>
</div>
<p><img alt="png" src="_images/output_7_1_3.png" /></p>
<p>Maximum separation on kernel 13, with a vertical dashed line.</p>
<center><b><u>A peroxisome logistic regression classifier</u></b></center>
<p>A peroxisome logistic regression classifier is a machine learning algorithm that is used to classify items based on their peroxisomal characteristics. This type of classifier can help identify items that are likely to be located within a peroxisome, as well as help to identify potential biomarkers for diseases associated with peroxisomal dysfunction. The classifier is trained on a dataset consisting of features associated with peroxisomes and then used to predict the presence or absence of a particular feature in an unknown sample. By training the classifier on a range of features, it is able to accurately predict the presence or absence of a feature in a given sample.</p>
<p>Here is the The logistic model used for classify peroxisome:</p>
<div style="text-align:center">
$y|\alpha,\beta,b  \sim Bernoulli(\theta)$<br/>
$\theta = logistic(\alpha + \beta \times b)$
</div>
<p><strong>The exponential decay equation</strong></p>
<p>$ t = a \times t0 \times e^{-b \times kernel}$\</p>
<p>where t is the current value of the decaying quantity, t0 is the initial value of the decaying quantity, a is a constant, b is the decay rate and kernel is the time interval over which the decay takes place.</p>
<p>$b =  - \frac {ln \frac {t}{t0}}{Kernel}$</p>
<p>The decay rate, b, is calculated by taking the natural logarithm of the ratio of the current value to the initial value and dividing it by the kernel.</p>
<p><strong>The Decay formula logistic model</strong> is a mathematical expression used to model the behaviour of a system over time. It is based on the idea that the rate of change in the system is proportional to the current state of the system. The equation is represented as:</p>
<p>$\theta = logistic(\alpha + \beta \frac {ln \frac {t}{t0}}{Kernel})$</p>
<p>Where:</p>
<p>$\theta$ is the output of the model, which describes the rate of change in the system.</p>
<p>The Normal distribution prior assigned to $\alpha$ and $\beta$ had a mean of 0 and a standard deviation of 10, which can be adjusted to control the behavior of the model.</p>
<p>$t$ is the current state of the system.</p>
<p>$t0$ is the initial state of the system.</p>
<p>$Kernel$ is the rate of change in the system.</p>
<p>The logistic part of the equation is used to ensure that the output is within a certain range. This range is defined by the parameters $a$ and $\beta$.</p>
<center><b><u>Logistic Regression Classifier, training</u></b></center>
<p>As demonstrated above, the <code class="docutils literal notranslate"><span class="pre">granularityMesure_cellpose</span></code> function performs a granularity analysis on the input image, producing a granularity table, e.g.</p>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</pre></div>
</div>
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>labeledCell</th>
      <th>kernel</th>
      <th>intensity</th>
      <th>classLabel</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>1.000000</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>2</td>
      <td>0.816656</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
<p>The data folder contains CSV files that have been generated by the <code class="docutils literal notranslate"><span class="pre">granularityMesure_cellpose</span></code> tool, which can be used to train a Bayes model.
Here, model is trained using 700 labeled single cells that have been segmented from 5 images.</p>
<p>:::{note}
The Bayesian classifier requires two CSV files, one for class 0 (phenotype) and one for class 1 (wild type)
e.g. norm.csv, pheno.csv
:::</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">AIPyS.Baysian_training</span> <span class="kn">import</span> <span class="n">bayesModelTraining</span>
<span class="n">pathIn</span> <span class="o">=</span>   <span class="s1">&#39;data&#39;</span>
<span class="n">files</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">pathname</span><span class="o">=</span><span class="n">pathIn</span><span class="o">+</span><span class="s2">&quot;\*.csv&quot;</span><span class="p">)</span>
<span class="n">Table_MergeFinel</span><span class="p">,</span> <span class="n">Table_MergeFinelFitelrd</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="n">y_0</span><span class="p">,</span> <span class="n">trace</span> <span class="o">=</span> <span class="n">bayesModelTraining</span><span class="p">(</span><span class="n">files</span> <span class="o">=</span> <span class="n">files</span><span class="p">,</span>  <span class="n">kernelSize</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">pathOut</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span><span class="n">reportFile</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
<p>Next, the similarities and differences between the classes are identified and evaluated.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>3.11.5
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Sequential sampling (2 chains in 1 job)
NUTS: [b, a]
</pre></div>
</div>
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
<div>
  <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>
  100.00% [8000/8000 00:53<00:00 Sampling chain 0, 0 divergences]
</div>
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
<div>
  <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>
  100.00% [8000/8000 00:44<00:00 Sampling chain 1, 0 divergences]
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Sampling 2 chains for 4_000 tune and 4_000 draw iterations (8_000 + 8_000 draws total) took 98 seconds.
The number of effective samples is smaller than 25% for some parameters.
</pre></div>
</div>
<p><img alt="png" src="_images/output_20_0_3.png" /></p>
<p>The trace-plot in pymc3 is a graphical representation of the sampling results obtained from a MCMC algorithm. It plots the sampled values of the parameters over the iterations, allowing the user to assess the convergence of the algorithm, as well as the overall distribution of the samples. The trace-plot can also be used to identify potential divergences, which indicate that the MCMC algorithm may not have properly converged. The trace-plot can also be used to identify potential areas of improvement, such as increasing the number of samples or adjusting the step size of the chain.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>array([[&lt;AxesSubplot:title={&#39;center&#39;:&#39;a&#39;}&gt;,
        &lt;AxesSubplot:title={&#39;center&#39;:&#39;a&#39;}&gt;],
       [&lt;AxesSubplot:title={&#39;center&#39;:&#39;b&#39;}&gt;,
        &lt;AxesSubplot:title={&#39;center&#39;:&#39;b&#39;}&gt;],
       [&lt;AxesSubplot:title={&#39;center&#39;:&#39;theta&#39;}&gt;,
        &lt;AxesSubplot:title={&#39;center&#39;:&#39;theta&#39;}&gt;],
       [&lt;AxesSubplot:title={&#39;center&#39;:&#39;bd&#39;}&gt;,
        &lt;AxesSubplot:title={&#39;center&#39;:&#39;bd&#39;}&gt;]], dtype=object)




&lt;Figure size 216x216 with 0 Axes&gt;
</pre></div>
</div>
<p><img alt="png" src="_images/output_22_2_3.png" /></p>
<p><b><u>Model evaluation </u></b>
The boundaries between classes are determined by the logistic function, which is used to calculate the probability of a data point belonging to a particular class. The model’s parameters are estimated based on the training data, and the model is then used to make predictions on unseen data.</p>
<p>$\theta = logistic(\alpha + \beta \times b)$
<Br/>
<Br/>
$bd = - \frac{\alpha}{\beta}$</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Text(0, 0.1, &#39;b :30.99&#39;)
</pre></div>
</div>
<p><img alt="png" src="_images/output_24_1_3.png" /></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="install/index.html" class="btn btn-neutral float-left" title="Installing AIPyS" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="API.html" class="btn btn-neutral float-right" title="AIPyS modules" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Gil Kanfer, PhD.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>