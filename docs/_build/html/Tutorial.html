<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Tutorials &mdash; AIPyS  documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="AIPyS modules" href="API.html" />
    <link rel="prev" title="Installing AIPyS" href="install/index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> AIPyS
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="install/index.html">Installing AIPyS</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Tutorials</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#parametric-segmentation">1 Parametric Segmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#deep-learning-segmentation">2 Deep learning Segmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#naive-bayes-algorithm-granularity-classifier">3 Naive Bayes Algorithm-Granularity Classifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="#baye-s-classifier-deployment">4 Baye’s Classifier - Deployment</a></li>
<li class="toctree-l2"><a class="reference internal" href="#convolutional-neural-network-classifier">5 Convolutional Neural Network - Classifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="#cnn-classifier-deployment">6 CNN Classifier - Deployment</a></li>
<li class="toctree-l2"><a class="reference internal" href="#enrichment-analysis-crisper-i-screen">7 Enrichment Analysis  - Crisper[i] Screen</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="API.html">AIPyS modules</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">AIPyS</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a></li>
      <li class="breadcrumb-item active">Tutorials</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/Tutorial.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="tutorials">
<h1>Tutorials<a class="headerlink" href="#tutorials" title="Permalink to this headline"></a></h1>
<section id="parametric-segmentation">
<h2>1 Parametric Segmentation<a class="headerlink" href="#parametric-segmentation" title="Permalink to this headline"></a></h2>
<p>The AIPS packdge provides two alternative methods for segmenting cells: parametric or deep-learning segmentation.
For parametric segmentation, we enhanced and translated our  <a class="reference external" href="https://www.r-project.org/">R</a>-based code.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">AIPyS</span> <span class="kn">import</span> <span class="n">AIPS_module</span> <span class="k">as</span> <span class="n">ai</span>
<span class="kn">from</span> <span class="nn">AIPyS</span> <span class="kn">import</span> <span class="n">AIPS_functions</span> <span class="k">as</span> <span class="n">af</span>
<span class="kn">from</span> <span class="nn">AIPyS</span> <span class="kn">import</span> <span class="n">AIPS_file_display</span> <span class="k">as</span> <span class="n">afd</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>F:\Gil\anaconda\envs\pm-tf24-cellpose\lib\site-packages\skimage\viewer\utils\__init__.py:1: UserWarning: Recommended matplotlib backend is `Agg` for full skimage.viewer functionality.
  from .core import *
</pre></div>
</div>
<p>We demonstrate the image segmentation of a capture of Catalase-GFP expressing u2os cells. This image was cropped from a 2044x2048 pixel image to a size of 512x512.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">io</span>
<span class="n">image_pex</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s1">&#39;catGFP.tif&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><img alt="png" src="_images/output_5_0_1.png" /></p>
<p>Set AIPyS object for preforming segmentation of the nucleus (seed),</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">AIPS_object</span> <span class="o">=</span> <span class="n">ai</span><span class="o">.</span><span class="n">Segmentation</span><span class="p">(</span><span class="n">Image_name</span><span class="o">=</span> <span class="s1">&#39;catGFP.tif&#39;</span><span class="p">,</span> <span class="n">path</span> <span class="o">=</span> <span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="n">ch_</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">rmv_object_nuc</span> <span class="o">=</span> <span class="mf">0.12</span><span class="p">,</span><span class="n">block_size</span> <span class="o">=</span> <span class="mi">59</span><span class="p">,</span> <span class="n">offset</span><span class="o">=-</span><span class="mi">4</span><span class="p">,</span> <span class="n">clean</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">seed</span> <span class="o">=</span> <span class="n">AIPS_object</span><span class="o">.</span><span class="n">seedSegmentation</span><span class="p">()</span>
<span class="n">nmask2</span> <span class="o">=</span> <span class="n">seed</span><span class="p">[</span><span class="s1">&#39;nmask2&#39;</span><span class="p">]</span> <span class="c1">#Local threshold map - seed</span>
<span class="n">sort_mask</span> <span class="o">=</span> <span class="n">seed</span><span class="p">[</span><span class="s1">&#39;sort_mask&#39;</span><span class="p">]</span> <span class="c1">#RGB map - seed</span>
</pre></div>
</div>
<p>Then object is used for segmenting based on the nucleus as a seed.
where the seed  segmentation parametrs are pluged in.
Calculate a threshold mask image by using a weighted mean (block_size) of the local neighborhood of each pixel, minus a offset.</p>
<p><img alt="png" src="_images/output_7_0_1.png" /></p>
<p>Target channel (Catalase-GFP) was used to identify cell borders and edges for segmentation. High-pass filtering, local thresholding, and global thresholding were then used to create global and local masks.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">target</span> <span class="o">=</span> <span class="n">AIPS_object</span><span class="o">.</span><span class="n">cytosolSegmentation</span><span class="p">(</span><span class="n">ch2_</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">block_size_cyto</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">offset_cyto</span><span class="o">=-</span><span class="mi">5</span><span class="p">,</span> <span class="n">global_ther</span><span class="o">=</span> <span class="mf">0.51</span><span class="p">,</span> <span class="n">rmv_object_cyto</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">rmv_object_cyto_small</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>
<span class="n">combine</span> <span class="o">=</span> <span class="n">target</span><span class="p">[</span><span class="s1">&#39;combine&#39;</span><span class="p">]</span>
<span class="n">cseg_mask</span> <span class="o">=</span> <span class="n">target</span><span class="p">[</span><span class="s1">&#39;cseg_mask&#39;</span><span class="p">]</span>
<span class="n">mask_unfiltered</span> <span class="o">=</span> <span class="n">target</span><span class="p">[</span><span class="s1">&#39;mask_unfiltered&#39;</span><span class="p">]</span>
<span class="n">maskContour</span> <span class="o">=</span> <span class="n">afd</span><span class="o">.</span><span class="n">Compsite_display</span><span class="p">(</span><span class="n">input_image</span> <span class="o">=</span> <span class="n">image_pex</span><span class="p">[</span><span class="mi">0</span><span class="p">,:,:],</span> <span class="n">mask_roi</span> <span class="o">=</span> <span class="n">cseg_mask</span><span class="p">,</span> <span class="n">channel</span><span class="o">=</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">draw_ROI_contour</span><span class="p">()</span>
</pre></div>
</div>
<p><img alt="png" src="_images/output_9_0_1.png" /></p>
</section>
<section id="deep-learning-segmentation">
<h2>2 Deep learning Segmentation<a class="headerlink" href="#deep-learning-segmentation" title="Permalink to this headline"></a></h2>
<p>The CellPose method (publish by Stinger et. al. ) uses a neural network (NN) to detect and segment cells from an input image. The NN is trained on a dataset of labeled images, with the labels indicating which pixels belong to each cell. After training, the network is able to accurately identify cells in a new image. CellPose also allows for the detection of multiple cells in an image, allowing for the analysis of cell colonies.</p>
<p>In conclusion, the CellPose method provides an efficient and accurate way to segment cells from microscopy images. This method can be used to analyze individual cells or cell colonies, allowing for the accurate measurement of cell features.</p>
<ul class="simple">
<li><p>Stringer, C., Wang, T., Michaelos, M., &amp; Pachitariu, M. (2021). Cellpose: a generalist algorithm for cellular segmentation. <em>Nature methods, 18</em>(1), 100-106.
[<a class="reference external" href="https://scholar.googleusercontent.com/scholar.bib?q=info:rmoKTp0cEiYJ:scholar.google.com/&amp;output=citation&amp;scisdr=CgXHFLYtEMb9qOfkmrg:AAGBfm0AAAAAY2jigrhA_p9qteLfyKDZlh96dZdapgkX&amp;scisig=AAGBfm0AAAAAY2jigv55oXhgKwSArS2sr_fxBh--42gU&amp;scisf=4&amp;ct=citation&amp;cd=-1&amp;hl=en&amp;scfhb=1">bibtex</a>] <Br></p></li>
<li><p><a class="reference external" href="https://github.com/MouseLand/cellpose">Cellpose github page</a></p></li>
</ul>
<p>We integrated Cellpose with the AIPS platform to enable automatic capture of cell borders.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">AIPyS</span> <span class="kn">import</span> <span class="n">AIPS_cellpose</span> <span class="k">as</span> <span class="n">AC</span>
</pre></div>
</div>
<p>In addation, the compsite_display module for display the mask contour</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">AIPyS</span> <span class="kn">import</span> <span class="n">AIPS_file_display</span> <span class="k">as</span> <span class="n">afd</span>
</pre></div>
</div>
<p>Similar to the parametric segmentation method, GFP-expressing Catalase images are uploaded and analyzed using the <code class="docutils literal notranslate"><span class="pre">AIPS_cellpose</span></code> module.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">AIPS_pose_object</span> <span class="o">=</span> <span class="n">AC</span><span class="o">.</span><span class="n">AIPS_cellpose</span><span class="p">(</span><span class="n">Image_name</span> <span class="o">=</span> <span class="s1">&#39;catGFP.tif&#39;</span><span class="p">,</span> <span class="n">path</span> <span class="o">=</span> <span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="n">model_type</span> <span class="o">=</span> <span class="s1">&#39;cyto&#39;</span><span class="p">,</span> <span class="n">channels</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">AIPS_pose_object</span><span class="o">.</span><span class="n">cellpose_image_load</span><span class="p">()</span>
</pre></div>
</div>
<p>The parameter <code class="docutils literal notranslate"><span class="pre">channels=[0,0]</span></code> indicates input grayscale image.</p>
<p>The module <code class="docutils literal notranslate"><span class="pre">cellpose_segmantation</span></code> calls for CellPose segmentation algorithm, and returns target mask (in this case “cyto”) and features table.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mask</span><span class="p">,</span> <span class="n">table</span> <span class="o">=</span> <span class="n">AIPS_pose_object</span><span class="o">.</span><span class="n">cellpose_segmantation</span><span class="p">(</span><span class="n">image_input</span><span class="o">=</span><span class="n">img</span><span class="p">[</span><span class="mi">0</span><span class="p">,:,:])</span>
</pre></div>
</div>
<p>Display cytosolic mask contour using the <code class="docutils literal notranslate"><span class="pre">Compsite_display</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">maskContour</span> <span class="o">=</span> <span class="n">afd</span><span class="o">.</span><span class="n">Compsite_display</span><span class="p">(</span><span class="n">input_image</span> <span class="o">=</span> <span class="n">img</span><span class="p">[</span><span class="mi">0</span><span class="p">,:,:],</span> <span class="n">mask_roi</span> <span class="o">=</span> <span class="n">mask</span><span class="p">,</span> <span class="n">channel</span><span class="o">=</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">draw_ROI_contour</span><span class="p">()</span>
</pre></div>
</div>
<p><img alt="png" src="_images/output_7_0_2.png" /></p>
</section>
<section id="naive-bayes-algorithm-granularity-classifier">
<h2>3 Naive Bayes Algorithm-Granularity Classifier<a class="headerlink" href="#naive-bayes-algorithm-granularity-classifier" title="Permalink to this headline"></a></h2>
<p>Naive Bayes Algorithm-Granularity Classifier</p>
<p>We will use AIPS platform to distinguish between peroxisome-positive and peroxisome-negative cells by imaging GFP-expressing Catalse. To model peroxisomes, we will use Pex13 mutant cells, with GFP-cat signal spread throughout the cytoplasm.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">AIPS_cellpose</span></code> module is used for segmenting input image cytoplasmic signal.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">AIPyS.AIPS_cellpose</span> <span class="kn">import</span> <span class="n">granularityMesure_cellpose</span>
</pre></div>
</div>
<p>Segment cells and measure area of each cell which is marked in red. In the cellular level, granularity will be analysed.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="n">wt</span><span class="p">,</span> <span class="n">WTtable</span><span class="p">,</span> <span class="n">WTdf</span> <span class="o">=</span> <span class="n">granularityMesure_cellpose</span><span class="p">(</span><span class="n">file</span> <span class="o">=</span> <span class="n">fileNmae</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">path</span> <span class="o">=</span> <span class="n">path</span><span class="p">,</span> <span class="n">classLabel</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
                               <span class="n">outPath</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">clean</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">outputTableName</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span><span class="n">saveMode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">intensity</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">kO</span><span class="p">,</span> <span class="n">kOtable</span><span class="p">,</span> <span class="n">kOdf</span> <span class="o">=</span> <span class="n">granularityMesure_cellpose</span><span class="p">(</span><span class="n">file</span> <span class="o">=</span> <span class="n">fileNmae</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">path</span> <span class="o">=</span> <span class="n">path</span><span class="p">,</span> <span class="n">classLabel</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
                               <span class="n">outPath</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">clean</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">outputTableName</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span><span class="n">saveMode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">intensity</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">wt</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">gray</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="s1">&#39;WT&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">ko</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">gray</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="s1">&#39;PEX3KO&#39;</span><span class="p">)</span>

</pre></div>
</div>
<p><img alt="png" src="_images/output_2_0_3.png" /></p>
<p>The method of analysis of granularity examines the effect of openings of increasing size on images of differing granularity. The volume of the open image is calculated as the sum of all pixels in each step, and the difference in volume between these successive steps is the granular spectrum. This granular spectrum is then normalized to the total volume (integrated intensity) of the image in order to create a diagram that displays how the different sizes of opening affect the images. Phenotype are assigned for training the model. For example, <strong>1</strong> for Pex3-KO and <strong>0</strong> for the WT cells. </Br>
Marge Granularity Table from both classes and plot Granularity spectrum.</p>
<style type="text/css">
#T_77728_ th {
  font-size: 8px;
  max-width: 50px;
}
#T_77728_ td {
  font-size: 8px;
  max-width: 50px;
}
</style>
<table id="T_77728_">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th class="col_heading level0 col0" >index</th>
      <th class="col_heading level0 col1" >kernel</th>
      <th class="col_heading level0 col2" >Signal intensity (ratio)</th>
      <th class="col_heading level0 col3" >classLabel</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_77728_level0_row0" class="row_heading level0 row0" >0</th>
      <td id="T_77728_row0_col0" class="data row0 col0" >0</td>
      <td id="T_77728_row0_col1" class="data row0 col1" >0</td>
      <td id="T_77728_row0_col2" class="data row0 col2" >1.000000</td>
      <td id="T_77728_row0_col3" class="data row0 col3" >0</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row1" class="row_heading level0 row1" >1</th>
      <td id="T_77728_row1_col0" class="data row1 col0" >1</td>
      <td id="T_77728_row1_col1" class="data row1 col1" >2</td>
      <td id="T_77728_row1_col2" class="data row1 col2" >0.890134</td>
      <td id="T_77728_row1_col3" class="data row1 col3" >0</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row2" class="row_heading level0 row2" >2</th>
      <td id="T_77728_row2_col0" class="data row2 col0" >2</td>
      <td id="T_77728_row2_col1" class="data row2 col1" >8</td>
      <td id="T_77728_row2_col2" class="data row2 col2" >0.656016</td>
      <td id="T_77728_row2_col3" class="data row2 col3" >0</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row3" class="row_heading level0 row3" >3</th>
      <td id="T_77728_row3_col0" class="data row3 col0" >3</td>
      <td id="T_77728_row3_col1" class="data row3 col1" >14</td>
      <td id="T_77728_row3_col2" class="data row3 col2" >0.513061</td>
      <td id="T_77728_row3_col3" class="data row3 col3" >0</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row4" class="row_heading level0 row4" >4</th>
      <td id="T_77728_row4_col0" class="data row4 col0" >4</td>
      <td id="T_77728_row4_col1" class="data row4 col1" >21</td>
      <td id="T_77728_row4_col2" class="data row4 col2" >0.381961</td>
      <td id="T_77728_row4_col3" class="data row4 col3" >0</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row5" class="row_heading level0 row5" >5</th>
      <td id="T_77728_row5_col0" class="data row5 col0" >5</td>
      <td id="T_77728_row5_col1" class="data row5 col1" >27</td>
      <td id="T_77728_row5_col2" class="data row5 col2" >0.282762</td>
      <td id="T_77728_row5_col3" class="data row5 col3" >0</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row6" class="row_heading level0 row6" >6</th>
      <td id="T_77728_row6_col0" class="data row6 col0" >6</td>
      <td id="T_77728_row6_col1" class="data row6 col1" >34</td>
      <td id="T_77728_row6_col2" class="data row6 col2" >0.221506</td>
      <td id="T_77728_row6_col3" class="data row6 col3" >0</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row7" class="row_heading level0 row7" >7</th>
      <td id="T_77728_row7_col0" class="data row7 col0" >7</td>
      <td id="T_77728_row7_col1" class="data row7 col1" >40</td>
      <td id="T_77728_row7_col2" class="data row7 col2" >0.190235</td>
      <td id="T_77728_row7_col3" class="data row7 col3" >0</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row8" class="row_heading level0 row8" >8</th>
      <td id="T_77728_row8_col0" class="data row8 col0" >8</td>
      <td id="T_77728_row8_col1" class="data row8 col1" >47</td>
      <td id="T_77728_row8_col2" class="data row8 col2" >0.157380</td>
      <td id="T_77728_row8_col3" class="data row8 col3" >0</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row9" class="row_heading level0 row9" >9</th>
      <td id="T_77728_row9_col0" class="data row9 col0" >9</td>
      <td id="T_77728_row9_col1" class="data row9 col1" >53</td>
      <td id="T_77728_row9_col2" class="data row9 col2" >0.139901</td>
      <td id="T_77728_row9_col3" class="data row9 col3" >0</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row10" class="row_heading level0 row10" >10</th>
      <td id="T_77728_row10_col0" class="data row10 col0" >10</td>
      <td id="T_77728_row10_col1" class="data row10 col1" >60</td>
      <td id="T_77728_row10_col2" class="data row10 col2" >0.127143</td>
      <td id="T_77728_row10_col3" class="data row10 col3" >0</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row11" class="row_heading level0 row11" >11</th>
      <td id="T_77728_row11_col0" class="data row11 col0" >0</td>
      <td id="T_77728_row11_col1" class="data row11 col1" >0</td>
      <td id="T_77728_row11_col2" class="data row11 col2" >1.000000</td>
      <td id="T_77728_row11_col3" class="data row11 col3" >1</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row12" class="row_heading level0 row12" >12</th>
      <td id="T_77728_row12_col0" class="data row12 col0" >1</td>
      <td id="T_77728_row12_col1" class="data row12 col1" >2</td>
      <td id="T_77728_row12_col2" class="data row12 col2" >0.951306</td>
      <td id="T_77728_row12_col3" class="data row12 col3" >1</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row13" class="row_heading level0 row13" >13</th>
      <td id="T_77728_row13_col0" class="data row13 col0" >2</td>
      <td id="T_77728_row13_col1" class="data row13 col1" >8</td>
      <td id="T_77728_row13_col2" class="data row13 col2" >0.848492</td>
      <td id="T_77728_row13_col3" class="data row13 col3" >1</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row14" class="row_heading level0 row14" >14</th>
      <td id="T_77728_row14_col0" class="data row14 col0" >3</td>
      <td id="T_77728_row14_col1" class="data row14 col1" >14</td>
      <td id="T_77728_row14_col2" class="data row14 col2" >0.732633</td>
      <td id="T_77728_row14_col3" class="data row14 col3" >1</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row15" class="row_heading level0 row15" >15</th>
      <td id="T_77728_row15_col0" class="data row15 col0" >4</td>
      <td id="T_77728_row15_col1" class="data row15 col1" >21</td>
      <td id="T_77728_row15_col2" class="data row15 col2" >0.637133</td>
      <td id="T_77728_row15_col3" class="data row15 col3" >1</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row16" class="row_heading level0 row16" >16</th>
      <td id="T_77728_row16_col0" class="data row16 col0" >5</td>
      <td id="T_77728_row16_col1" class="data row16 col1" >27</td>
      <td id="T_77728_row16_col2" class="data row16 col2" >0.482065</td>
      <td id="T_77728_row16_col3" class="data row16 col3" >1</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row17" class="row_heading level0 row17" >17</th>
      <td id="T_77728_row17_col0" class="data row17 col0" >6</td>
      <td id="T_77728_row17_col1" class="data row17 col1" >34</td>
      <td id="T_77728_row17_col2" class="data row17 col2" >0.363300</td>
      <td id="T_77728_row17_col3" class="data row17 col3" >1</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row18" class="row_heading level0 row18" >18</th>
      <td id="T_77728_row18_col0" class="data row18 col0" >7</td>
      <td id="T_77728_row18_col1" class="data row18 col1" >40</td>
      <td id="T_77728_row18_col2" class="data row18 col2" >0.292876</td>
      <td id="T_77728_row18_col3" class="data row18 col3" >1</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row19" class="row_heading level0 row19" >19</th>
      <td id="T_77728_row19_col0" class="data row19 col0" >8</td>
      <td id="T_77728_row19_col1" class="data row19 col1" >47</td>
      <td id="T_77728_row19_col2" class="data row19 col2" >0.254713</td>
      <td id="T_77728_row19_col3" class="data row19 col3" >1</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row20" class="row_heading level0 row20" >20</th>
      <td id="T_77728_row20_col0" class="data row20 col0" >9</td>
      <td id="T_77728_row20_col1" class="data row20 col1" >53</td>
      <td id="T_77728_row20_col2" class="data row20 col2" >0.240333</td>
      <td id="T_77728_row20_col3" class="data row20 col3" >1</td>
    </tr>
    <tr>
      <th id="T_77728_level0_row21" class="row_heading level0 row21" >21</th>
      <td id="T_77728_row21_col0" class="data row21 col0" >10</td>
      <td id="T_77728_row21_col1" class="data row21 col1" >60</td>
      <td id="T_77728_row21_col2" class="data row21 col2" >0.232534</td>
      <td id="T_77728_row21_col3" class="data row21 col3" >1</td>
    </tr>
  </tbody>
</table>
<p>Merging the granularity tables and ploting granularity spectrom over time:
<code class="docutils literal notranslate"><span class="pre">python</span>&#160;&#160;&#160;&#160; <span class="pre">GranPerCell</span> <span class="pre">=</span> <span class="pre">pd.concat((WTgTable,kOgTable))</span>&#160;&#160;&#160;&#160; </code></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.lines.Line2D at 0x1e217f56488&gt;
</pre></div>
</div>
<p><img alt="png" src="_images/output_7_1_3.png" /></p>
<p>Maximum separation on kernel 13, with a vertical dashed line.</p>
<center><b><u>A peroxisome logistic regression classifier</u></b></center>
<p>A peroxisome logistic regression classifier is a machine learning algorithm that is used to classify items based on their peroxisomal characteristics. This type of classifier can help identify items that are likely to be located within a peroxisome, as well as help to identify potential biomarkers for diseases associated with peroxisomal dysfunction. The classifier is trained on a dataset consisting of features associated with peroxisomes and then used to predict the presence or absence of a particular feature in an unknown sample. By training the classifier on a range of features, it is able to accurately predict the presence or absence of a feature in a given sample.</p>
<p>Here is the The logistic model used for classify peroxisome:</p>
<div class="math notranslate nohighlight">
\[y|\alpha,\beta,b  \sim Bernoulli(\theta)
\theta = logistic(\alpha + \beta \times b)\]</div>
<p><strong>The exponential decay equation</strong></p>
<div class="math notranslate nohighlight">
\[t = a \times t0 \times e^{-b \times kernel}\]</div>
<p>where t is the current value of the decaying quantity, t0 is the initial value of the decaying quantity, a is a constant, b is the decay rate and kernel is the time interval over which the decay takes place.</p>
<div class="math notranslate nohighlight">
\[b =  - \frac {ln \frac {t}{t0}}{Kernel}\]</div>
<p>The decay rate, b, is calculated by taking the natural logarithm of the ratio of the current value to the initial value and dividing it by the kernel.</p>
<p><strong>The Decay formula logistic model</strong> is a mathematical expression used to model the behaviour of a system over time. It is based on the idea that the rate of change in the system is proportional to the current state of the system. The equation is represented as:</p>
<div class="math notranslate nohighlight">
\[\theta = logistic(\alpha + \beta \frac {ln \frac {t}{t0}}{Kernel})\]</div>
<p>Where:</p>
<p><code class="docutils literal notranslate"><span class="pre">{math}\theta</span></code> is the output of the model, which describes the rate of change in the system.</p>
<p>The Normal distribution prior assigned to $\alpha$ and $\beta$ had a mean of 0 and a standard deviation of 10, which can be adjusted to control the behavior of the model.</p>
<p><code class="docutils literal notranslate"><span class="pre">{math}t</span></code> is the current state of the system.</p>
<p><code class="docutils literal notranslate"><span class="pre">{math}t0</span></code> is the initial state of the system.</p>
<p><code class="docutils literal notranslate"><span class="pre">{math}Kernel</span></code> is the rate of change in the system.</p>
<p>The logistic part of the equation is used to ensure that the output is within a certain range. This range is defined by the parameters <code class="docutils literal notranslate"><span class="pre">{math}a</span></code> and <code class="docutils literal notranslate"><span class="pre">{math}\beta</span></code>.</p>
<center><b><u>Logistic Regression Classifier, training</u></b></center>
<p>As demonstrated above, the <code class="docutils literal notranslate"><span class="pre">granularityMesure_cellpose</span></code> function performs a granularity analysis on the input image, producing a granularity table, e.g.</p>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</pre></div>
</div>
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>labeledCell</th>
      <th>kernel</th>
      <th>intensity</th>
      <th>classLabel</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>1.000000</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>2</td>
      <td>0.816656</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
<p>The data folder contains CSV files that have been generated by the <code class="docutils literal notranslate"><span class="pre">granularityMesure_cellpose</span></code> tool, which can be used to train a Bayes model.
Here, model is trained using 700 labeled single cells that have been segmented from 5 images.</p>
<p>:::{note}
The Bayesian classifier requires two CSV files, one for class 0 (phenotype) and one for class 1 (wild type)
e.g. norm.csv, pheno.csv
:::</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">AIPyS.Baysian_training</span> <span class="kn">import</span> <span class="n">bayesModelTraining</span>
<span class="n">pathIn</span> <span class="o">=</span>   <span class="s1">&#39;data&#39;</span>
<span class="n">files</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">pathname</span><span class="o">=</span><span class="n">pathIn</span><span class="o">+</span><span class="s2">&quot;\*.csv&quot;</span><span class="p">)</span>
<span class="n">Table_MergeFinel</span><span class="p">,</span> <span class="n">Table_MergeFinelFitelrd</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="n">y_0</span><span class="p">,</span> <span class="n">trace</span> <span class="o">=</span> <span class="n">bayesModelTraining</span><span class="p">(</span><span class="n">files</span> <span class="o">=</span> <span class="n">files</span><span class="p">,</span>  <span class="n">kernelSize</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">pathOut</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span><span class="n">reportFile</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
<p>Next, the similarities and differences between the classes are identified and evaluated.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>3.11.5
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Sequential sampling (2 chains in 1 job)
NUTS: [b, a]
</pre></div>
</div>
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
<div>
  <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>
  100.00% [8000/8000 00:53<00:00 Sampling chain 0, 0 divergences]
</div>
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
<div>
  <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>
  100.00% [8000/8000 00:44<00:00 Sampling chain 1, 0 divergences]
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Sampling 2 chains for 4_000 tune and 4_000 draw iterations (8_000 + 8_000 draws total) took 98 seconds.
The number of effective samples is smaller than 25% for some parameters.
</pre></div>
</div>
<p><img alt="png" src="_images/output_20_0_3.png" /></p>
<p>The trace-plot in pymc3 is a graphical representation of the sampling results obtained from a MCMC algorithm. It plots the sampled values of the parameters over the iterations, allowing the user to assess the convergence of the algorithm, as well as the overall distribution of the samples. The trace-plot can also be used to identify potential divergences, which indicate that the MCMC algorithm may not have properly converged. The trace-plot can also be used to identify potential areas of improvement, such as increasing the number of samples or adjusting the step size of the chain.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>array([[&lt;AxesSubplot:title={&#39;center&#39;:&#39;a&#39;}&gt;,
        &lt;AxesSubplot:title={&#39;center&#39;:&#39;a&#39;}&gt;],
       [&lt;AxesSubplot:title={&#39;center&#39;:&#39;b&#39;}&gt;,
        &lt;AxesSubplot:title={&#39;center&#39;:&#39;b&#39;}&gt;],
       [&lt;AxesSubplot:title={&#39;center&#39;:&#39;theta&#39;}&gt;,
        &lt;AxesSubplot:title={&#39;center&#39;:&#39;theta&#39;}&gt;],
       [&lt;AxesSubplot:title={&#39;center&#39;:&#39;bd&#39;}&gt;,
        &lt;AxesSubplot:title={&#39;center&#39;:&#39;bd&#39;}&gt;]], dtype=object)




&lt;Figure size 216x216 with 0 Axes&gt;
</pre></div>
</div>
<p><img alt="png" src="_images/output_22_2_3.png" /></p>
<p><b><u>Model evaluation </u></b>
The boundaries between classes are determined by the logistic function, which is used to calculate the probability of a data point belonging to a particular class. The model’s parameters are estimated based on the training data, and the model is then used to make predictions on unseen data.</p>
<div class="math notranslate nohighlight">
\[\theta = logistic(\alpha + \beta \times b)\]</div>
<div class="math notranslate nohighlight">
\[\bd = - \frac{\alpha}{\beta}\]</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Text(0, 0.1, &#39;b :30.99&#39;)
</pre></div>
</div>
<p><img alt="png" src="_images/output_24_1_3.png" /></p>
</section>
<section id="baye-s-classifier-deployment">
<h2>4 Baye’s Classifier - Deployment<a class="headerlink" href="#baye-s-classifier-deployment" title="Permalink to this headline"></a></h2>
<p>Baye’s Classifier - Deployment</p>
<p>The Baye’s Granularity model created is exported and then utilized for deployment on the Nikon NIS Elements HCT package. A bash file was employed to direct the NIS jobs module to utilize AIPyS. The AIPys granularity classifier requires several parameters to assess the granularity resulting from the Baye’s Granularity training.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>@echo on
call activate AIPys_conda_env
call python D:<span class="se">\r</span>un_Bayes_Classifier.py
@pause
</pre></div>
</div>
<p>When obtaining an image, a single-channel image is taken and then stored on the local system.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">AIPyS.Baysian_deploy</span> <span class="kn">import</span> <span class="n">BayesianGranularityDeploy</span>
<span class="n">file</span> <span class="o">=</span> <span class="s1">&#39;input.tif&#39;</span>
<span class="n">path_input</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">&#39;C:\NIS\outproc&#39;</span>
<span class="n">path_out</span> <span class="o">=</span> <span class="n">path_input</span>

<span class="n">BayesianGranularityDeploy</span><span class="p">(</span><span class="n">file</span> <span class="o">=</span> <span class="n">file</span><span class="p">,</span> <span class="n">path</span> <span class="o">=</span> <span class="n">path_input</span><span class="p">,</span> <span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="n">trace_a</span> <span class="o">=</span> <span class="o">-</span><span class="mi">27</span><span class="p">,</span> <span class="n">trace_b</span> <span class="o">=</span> <span class="mi">33</span><span class="p">,</span>
                          <span class="n">thold</span> <span class="o">=</span> <span class="mf">0.7</span><span class="p">,</span>   <span class="n">pathOut</span> <span class="o">=</span> <span class="n">path_out</span><span class="p">,</span><span class="n">clean</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span><span class="n">saveMerge</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>The BayesianGranularityDeploy function returns a binary mask of the cells that represent the chosen phenotype. This mask is saved as <code class="docutils literal notranslate"><span class="pre">binary.tif</span></code> and then uploaded to the NIS-Elements module, where it is converted into a Region of Interest (ROI). The simulation module then takes the photostimulation raster and uses a UV laser to activate those regions.</p>
</section>
<section id="convolutional-neural-network-classifier">
<h2>5 Convolutional Neural Network - Classifier<a class="headerlink" href="#convolutional-neural-network-classifier" title="Permalink to this headline"></a></h2>
<p>Convolutional Neural Network - Classifier</p>
<p>For training the CNN peroxisome model, we utilized Pex13 mutant cells, which expressed GFP-Cat signals throughout their cytoplasm.</p>
<p>The Classification diverged into three parts:</p>
<ol class="arabic simple">
<li><p>Set training data</p></li>
<li><p>Model Generation</p></li>
<li><p>Evaluation</p></li>
</ol>
<center><b><u>Set training data</u></b></center>
<p>The GFP-Cat images were then segmented into individual cells and saved into two separate folders - one for phenotypic images and another for normal peroxisomes.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">AIPyS</span> <span class="kn">import</span> <span class="n">AIPS_cellpose</span> <span class="k">as</span> <span class="n">AC</span>
</pre></div>
</div>
<p>For example, we used the CellPose model for segmenting the images (as described in section 2):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">AIPS_pose_object</span> <span class="o">=</span> <span class="n">AC</span><span class="o">.</span><span class="n">AIPS_cellpose</span><span class="p">(</span><span class="n">Image_name</span> <span class="o">=</span> <span class="s1">&#39;catGFP.tif&#39;</span><span class="p">,</span> <span class="n">path</span> <span class="o">=</span> <span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="n">model_type</span> <span class="o">=</span> <span class="s1">&#39;cyto&#39;</span><span class="p">,</span> <span class="n">channels</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">AIPS_pose_object</span><span class="o">.</span><span class="n">cellpose_image_load</span><span class="p">()</span>
</pre></div>
</div>
<p>The function <code class="docutils literal notranslate"><span class="pre">stackObjects_cellpose_ebimage_parametrs_method</span></code> similar to the R packadge EBimage (publish by Pau et. al. ) brekes the mask input into 150 pixel single-cell images.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">AIPS_pose_object</span> <span class="o">=</span> <span class="n">AC</span><span class="o">.</span><span class="n">stackObjects_cellpose_ebimage_parametrs_method</span><span class="p">(</span><span class="n">Image_name</span> <span class="o">=</span> <span class="s1">&#39;catGFP.tif&#39;</span><span class="p">,</span> <span class="n">path</span> <span class="o">=</span> <span class="s1">&#39;data&#39;</span><span class="p">,</span>                                                                          <span class="n">model_type</span> <span class="o">=</span> <span class="s1">&#39;cyto&#39;</span><span class="p">,</span> <span class="n">channels</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">AIPS_pose_object</span><span class="o">.</span><span class="n">cellpose_image_load</span><span class="p">()</span>
<span class="n">mask</span><span class="p">,</span> <span class="n">table</span> <span class="o">=</span> <span class="n">AIPS_pose_object</span><span class="o">.</span><span class="n">cellpose_segmantation</span><span class="p">(</span><span class="n">image_input</span><span class="o">=</span><span class="n">img</span><span class="p">[</span><span class="mi">0</span><span class="p">,:,:])</span>

<span class="c1">##### Than EBimage like stacking function is used</span>

<span class="n">stack</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">AIPS_pose_object</span><span class="o">.</span><span class="n">stackObjects_cellpose_ebimage_parametrs_method</span><span class="p">(</span><span class="n">image_input</span><span class="o">=</span><span class="n">img</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:],</span>
                                                                           <span class="n">extract_pixel</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                                                                           <span class="n">resize_pixel</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span>
                                                                           <span class="n">img_label</span><span class="o">=</span><span class="n">table</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>


</pre></div>
</div>
<ul class="simple">
<li><p>Pau G, Fuchs F, Sklyar O, Boutros M, Huber W (2010). “EBImage—an R package for image processing with applications to cellular phenotypes.” Bioinformatics, 26(7), 979–981. doi: 10.1093/bioinformatics/btq046.</p></li>
</ul>
<p>The single-cell images are to be organized into a training structure consisting of three separate directories, training_data, validation_data and test_data, each containing two folders; one for positive samples (pheno) and one for negative samples (norm). The data is then ready to be used for machine learning model training and validation.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">AIPyS</span> <span class="kn">import</span> <span class="n">Taining_data_orgenizer</span> <span class="k">as</span> <span class="n">orgenizer</span>


<span class="n">pathInput</span> <span class="o">=</span> <span class="s1">&#39;/input_sc_mix&#39;</span>
<span class="n">pathOrigen</span> <span class="o">=</span> <span class="s1">&#39;/data/training_set&#39;</span>
<span class="n">labelA</span> <span class="o">=</span> <span class="s1">&#39;norm&#39;</span>
<span class="n">labelB</span> <span class="o">=</span> <span class="s1">&#39;pheno&#39;</span>
<span class="n">file_extention</span> <span class="o">=</span> <span class="s1">&#39;png&#39;</span>


<span class="n">path_builder</span> <span class="o">=</span> <span class="n">orgenizer</span><span class="o">.</span><span class="n">classification_data_orgenizer</span><span class="p">(</span><span class="n">path_input</span> <span class="o">=</span> <span class="n">pathInput</span><span class="p">,</span>
                                                       <span class="n">path_origen</span> <span class="o">=</span> <span class="n">pathOrigen</span><span class="p">,</span>
                                                       <span class="n">label_A</span><span class="o">=</span><span class="n">labelA</span><span class="p">,</span>
                                                       <span class="n">label_B</span> <span class="o">=</span><span class="n">labelB</span><span class="p">,</span>
                                                       <span class="n">file_extention</span> <span class="o">=</span><span class="n">file_extention</span><span class="p">)</span>

<span class="n">path_builder</span><span class="o">.</span><span class="n">get_file_names_list</span><span class="p">()</span>

<span class="n">statment_a</span><span class="p">,</span> <span class="n">statment_b</span><span class="p">,</span> <span class="n">train_files</span><span class="p">,</span> <span class="n">validate_files</span><span class="p">,</span> <span class="n">test_files</span> <span class="o">=</span> <span class="n">path_builder</span><span class="o">.</span><span class="n">split_traning_set_and_copy</span><span class="p">()</span>

</pre></div>
</div>
<p>Directory structure:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>training_set
│
└───training_data
|       │phno01.png
│       │norm01.png
│       │...
│
└───validation_data
|       │pheno02.png
│       │norm02.png
│       │...
└───test_data
        │pheno03.png
        │norm03.pn
        │...
</pre></div>
</div>
<center><b><u>Model Generation</u></b></center>
<p>The plotform contain four CNN models.</p>
<ul class="simple">
<li><p>Basic CNN model</p></li>
<li><p>Basic CNN model with data Augmentation</p></li>
<li><p>Transfer learning drop layer 4 and 5</p></li>
<li><p>Transfer learning with Augmentation freez all layer</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">AIPyS</span> <span class="kn">import</span> <span class="n">model_builder</span> <span class="k">as</span> <span class="n">mb</span>
</pre></div>
</div>
<p>We set hyperparamters for the model</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">train_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path_origen</span><span class="p">,</span> <span class="s1">&#39;training_data&#39;</span><span class="p">)</span>
<span class="n">val_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path_origen</span><span class="p">,</span> <span class="s1">&#39;validation_data&#39;</span><span class="p">)</span>
<span class="n">test_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path_origen</span><span class="p">,</span> <span class="s1">&#39;test_data&#39;</span><span class="p">)</span>
<span class="n">batch</span>  <span class="o">=</span> <span class="mi">30</span>
<span class="n">epoch</span>  <span class="o">=</span> <span class="mi">50</span>
<span class="n">step_per_epoch</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="mi">9930</span><span class="p">)</span><span class="o">/</span><span class="mi">30</span><span class="p">)</span>
<span class="n">validation_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="mi">1242</span><span class="p">)</span><span class="o">/</span><span class="mi">30</span><span class="p">)</span>
<span class="n">path_model</span> <span class="o">=</span> <span class="s1">&#39;/data/models&#39;</span>
<span class="n">IMG_DIM</span><span class="o">=</span><span class="p">(</span><span class="mi">150</span><span class="p">,</span><span class="mi">150</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">imbalance_train</span> <span class="o">=</span> <span class="mi">921</span>
<span class="n">imbalance_val</span> <span class="o">=</span> <span class="mi">115</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s1">&#39;10precent.h5&#39;</span>
<span class="n">path_checkpoints</span> <span class="o">=</span> <span class="s1">&#39;/data/models/chakpoints_10p/&#39;</span>
</pre></div>
</div>
<p>Intiate model bulider:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model_build</span> <span class="o">=</span> <span class="n">mb</span><span class="o">.</span><span class="n">model_builder</span><span class="p">(</span><span class="n">IMG_DIM</span><span class="o">=</span><span class="p">(</span><span class="mi">150</span><span class="p">,</span><span class="mi">150</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span><span class="n">path_training</span><span class="o">=</span><span class="n">train_dir</span><span class="p">,</span><span class="n">path_validation</span><span class="o">=</span><span class="n">val_dir</span><span class="p">,</span>
                 <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">epoch</span> <span class="o">=</span> <span class="n">epoch</span><span class="p">,</span><span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">150</span><span class="p">,</span><span class="mi">150</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span> <span class="p">,</span><span class="n">steps_per_epoch_sel</span><span class="o">=</span> <span class="n">step_per_epoch</span><span class="p">,</span>
                 <span class="n">validation_steps</span><span class="o">=</span><span class="n">validation_steps</span><span class="p">,</span><span class="n">path_model</span> <span class="o">=</span> <span class="n">path_model</span><span class="p">,</span><span class="n">file_extention</span> <span class="o">=</span> <span class="s1">&#39;png&#39;</span><span class="p">,</span>
                 <span class="n">extract_size_train</span> <span class="o">=</span> <span class="n">extract_size_train</span><span class="p">,</span> <span class="n">extract_size_val</span><span class="o">=</span><span class="n">extract_size_val</span><span class="p">)</span>
</pre></div>
</div>
<p>Image files are loaded and converted to tf tensor.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">TRimgScale</span><span class="p">,</span><span class="n">ValimgScale</span><span class="p">,</span><span class="n">TRlabels</span><span class="p">,</span><span class="n">Valabels</span><span class="p">,</span><span class="n">TRimg</span><span class="p">,</span><span class="n">Valimg</span><span class="p">,</span><span class="n">report</span> <span class="o">=</span> <span class="n">model_build</span><span class="o">.</span><span class="n">build_image__sets</span><span class="p">()</span>
<span class="nb">print</span> <span class="n">report</span>
</pre></div>
</div>
<p>tarin labels:[‘norm’, ‘pheno’, ‘norm’, ‘norm’, ‘norm’], train_labels_enc:[0 1 0 0 0].</p>
<p>Train models:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cnn_basic</span> <span class="o">=</span> <span class="n">model_build</span><span class="o">.</span><span class="n">model_cnn_basic</span><span class="p">()</span>
<span class="n">cnn_basic_Augmentation</span> <span class="o">=</span> <span class="n">model_build</span><span class="o">.</span><span class="n">model_cnn_basic_Augmentation</span><span class="p">()</span>
<span class="n">cnn_transfer_learning_Augmentation_drop_layer_4and5</span>  <span class="o">=</span>           <span class="n">model_build</span><span class="o">.</span><span class="n">model_cnn_transfer_learning_Augmentation_drop_layer_4and5</span><span class="p">()</span>
<span class="n">transfer_learning_aug_dropout_freez_all</span> <span class="o">=</span> <span class="n">model_build</span><span class="o">.</span><span class="n">model_cnn_transfer_learning_Augmentation_freez_all</span><span class="p">()</span>
</pre></div>
</div>
<center><b><u>Evaluation</u></b></center>
<p>Assess the efficacy of the model constructed by assessing its performance.
First, the test files will be converted into tensors of model input pixel size.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">test_imgs</span> <span class="o">=</span> <span class="p">[</span><span class="n">img_to_array</span><span class="p">(</span><span class="n">load_img</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">target_size</span><span class="o">=</span><span class="n">IMG_DIM</span><span class="p">))</span> <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">test_files</span><span class="p">]</span>
<span class="n">test_imgs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_imgs</span><span class="p">)</span>
<span class="n">test_imgs_scaled</span> <span class="o">=</span> <span class="n">test_imgs</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>
<span class="n">test_imgs_scaled</span> <span class="o">/=</span> <span class="mi">255</span>
</pre></div>
</div>
<p>The labels are assigned an integer value to be encoded.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">test_labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">fn</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">test_files</span><span class="p">]</span>
<span class="n">num2class_label_transformer</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">l</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;norm&#39;</span> <span class="k">if</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="s1">&#39;pheno&#39;</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">l</span><span class="p">]</span>
<span class="n">class2num_label_transformer</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">l</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="s1">&#39;pheno&#39;</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">l</span><span class="p">]</span>
<span class="n">test_labels_enc</span> <span class="o">=</span> <span class="n">class2num_label_transformer</span><span class="p">(</span><span class="n">test_labels</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test dataset shape:</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_imgs</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">test_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">],</span> <span class="n">test_labels_enc</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># {code-cell} ipython3</span>
<span class="c1"># :tags: [hide-input]</span>


<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.applications.vgg16</span> <span class="kn">import</span> <span class="n">VGG16</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing</span> <span class="kn">import</span> <span class="n">image</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.applications.vgg16</span> <span class="kn">import</span> <span class="n">preprocess_input</span><span class="p">,</span> <span class="n">decode_predictions</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">shutil</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing.image</span> <span class="kn">import</span> <span class="n">ImageDataGenerator</span><span class="p">,</span> <span class="n">load_img</span><span class="p">,</span> <span class="n">img_to_array</span><span class="p">,</span> <span class="n">array_to_img</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">MaxPooling2D</span><span class="p">,</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Dropout</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">optimizers</span>

<span class="kn">from</span> <span class="nn">keras.applications</span> <span class="kn">import</span> <span class="n">vgg16</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">import</span> <span class="nn">keras</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>


<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">MaxPooling2D</span><span class="p">,</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">InputLayer</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">optimizers</span>

<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing.image</span> <span class="kn">import</span> <span class="n">load_img</span><span class="p">,</span> <span class="n">img_to_array</span><span class="p">,</span> <span class="n">array_to_img</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="s1">&#39;/data/kanferg/Images/Pex_project/Transfer_learning/code&#39;</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">model_evaluation_utils</span> <span class="k">as</span> <span class="n">meu</span>

<span class="n">IMG_DIM</span> <span class="o">=</span> <span class="p">(</span><span class="mi">150</span><span class="p">,</span> <span class="mi">150</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="s2">&quot;/data/kanferg/Images/Pex_project/SIngle_cell_images_training_set/&quot;</span><span class="p">)</span>
<span class="n">test_files</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s1">&#39;test_data/*&#39;</span><span class="p">)</span>
<span class="n">test_imgs</span> <span class="o">=</span> <span class="p">[</span><span class="n">img_to_array</span><span class="p">(</span><span class="n">load_img</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">target_size</span><span class="o">=</span><span class="n">IMG_DIM</span><span class="p">))</span> <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">test_files</span><span class="p">]</span>
<span class="n">test_imgs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_imgs</span><span class="p">)</span>
<span class="c1">#test_files[0].split(&#39;/&#39;)[1].split(&#39;_&#39;)[0].strip()</span>
<span class="n">test_labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">fn</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">fn</span> <span class="ow">in</span> <span class="n">test_files</span><span class="p">]</span>
<span class="c1">#test_labels = [fn.split(&#39;/&#39;)[1].split(&#39;.&#39;)[0].strip() for fn in test_files]</span>

<span class="n">test_imgs_scaled</span> <span class="o">=</span> <span class="n">test_imgs</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>
<span class="n">test_imgs_scaled</span> <span class="o">/=</span> <span class="mi">255</span>
<span class="n">num2class_label_transformer</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">l</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;norm&#39;</span> <span class="k">if</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="s1">&#39;pheno&#39;</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">l</span><span class="p">]</span>
<span class="n">class2num_label_transformer</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">l</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="s1">&#39;pheno&#39;</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">l</span><span class="p">]</span>
<span class="n">test_labels_enc</span> <span class="o">=</span> <span class="n">class2num_label_transformer</span><span class="p">(</span><span class="n">test_labels</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test dataset shape:</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_imgs</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">test_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">],</span> <span class="n">test_labels_enc</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">])</span>

</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Test dataset shape:(5967, 150, 150, 3)
[&#39;norm&#39;, &#39;pheno&#39;, &#39;norm&#39;, &#39;pheno&#39;, &#39;norm&#39;] [1, 0, 1, 0, 1]
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">cnn_transfer_learning_Augmentation_drop_layer_4and5</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_imgs_scaled</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># {code-cell} ipython3</span>
<span class="c1"># :tags: [hide-input]</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="n">path_model</span> <span class="o">=</span> <span class="s1">&#39;/data/kanferg/Images/Pex_project/Transfer_learning/models&#39;</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="n">path_model</span><span class="p">)</span>
<span class="n">cnn_transfer_learning_Augmentation_drop_layer_4and5</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s1">&#39;cnn_transfer_learning_Augmentation_drop_layer_4and5.h5&#39;</span><span class="p">)</span>

<span class="n">predictions</span> <span class="o">=</span> <span class="n">cnn_transfer_learning_Augmentation_drop_layer_4and5</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_imgs_scaled</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="c1"># classes_x=[np.where(lab &gt;0.5,1,0).tolist() for lab in predictions]</span>
<span class="c1"># predictions_label = num2class_label_transformer(classes_x)</span>
<span class="c1"># predictions_label</span>

<span class="c1"># meu.get_metrics(test_labels, predictions_label)</span>

</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>(array([1.131e+03, 6.000e+00, 4.000e+00, 4.000e+00, 3.000e+00, 4.000e+00,
        6.000e+00, 5.000e+00, 7.000e+00, 4.797e+03]),
 array([0.00314956, 0.1028346 , 0.20251964, 0.3022047 , 0.40188974,
        0.50157475, 0.6012598 , 0.70094484, 0.8006299 , 0.9003149 ,
        1.        ], dtype=float32),
 &lt;BarContainer object of 10 artists&gt;)
</pre></div>
</div>
<p><img alt="png" src="_images/output_11_4.png" /></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">classes_x</span><span class="o">=</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">lab</span> <span class="o">&gt;</span><span class="mf">0.5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="k">for</span> <span class="n">lab</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">]</span>
<span class="n">predictions_label</span> <span class="o">=</span> <span class="n">num2class_label_transformer</span><span class="p">(</span><span class="n">classes_x</span><span class="p">)</span>
<span class="n">predictions_label</span>
<span class="n">meu</span><span class="o">.</span><span class="n">get_metrics</span><span class="p">(</span><span class="n">test_labels</span><span class="p">,</span> <span class="n">predictions_label</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># {code-cell} ipython3</span>
<span class="c1"># :tags: [hide-input]</span>

<span class="n">classes_x</span><span class="o">=</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">lab</span> <span class="o">&gt;</span><span class="mf">0.5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="k">for</span> <span class="n">lab</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">]</span>
<span class="n">predictions_label</span> <span class="o">=</span> <span class="n">num2class_label_transformer</span><span class="p">(</span><span class="n">classes_x</span><span class="p">)</span>
<span class="n">predictions_label</span>
<span class="n">meu</span><span class="o">.</span><span class="n">get_metrics</span><span class="p">(</span><span class="n">test_labels</span><span class="p">,</span> <span class="n">predictions_label</span><span class="p">)</span>

</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Accuracy: 0.9943
Precision: 0.9944
Recall: 0.9943
F1 Score: 0.9943
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</section>
<section id="cnn-classifier-deployment">
<h2>6 CNN Classifier - Deployment<a class="headerlink" href="#cnn-classifier-deployment" title="Permalink to this headline"></a></h2>
<p>Instead of using Bayes Granularity to deploy a model, the AIPyS Convolutional Neural Network (CNN) model can be used for detecting the desired phenotypes. To use the CNN model, it must be exported and then utilized with the Nikon NIS Elements HCT package. A bash file is used to instruct the NIS jobs module to run the AIPyS.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>@echo on
call activate AIPys_conda_env
call python D:<span class="se">\r</span>un_CNN_Classifier.py
@pause
</pre></div>
</div>
<p>When obtaining an image, a single-channel image is taken and then stored on the local system.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">AIPyS.Baysian_deploy</span> <span class="kn">import</span> <span class="n">BayesianGranularityDeploy</span>
<span class="n">file_name</span> <span class="o">=</span> <span class="s1">&#39;input.tif&#39;</span>
<span class="n">path_model</span> <span class="o">=</span> <span class="s1">&#39;data&#39;</span>
<span class="n">path_input</span> <span class="o">=</span> <span class="s1">&#39;C:\NIS\outproc&#39;</span>
<span class="n">path_out</span> <span class="o">=</span> <span class="n">path_input</span>

<span class="n">CNNDeploy</span><span class="p">(</span><span class="n">path_model</span> <span class="o">=</span> <span class="n">path_model</span><span class="p">,</span> <span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;cnn.h5&#39;</span><span class="p">,</span>
          <span class="n">file_name</span> <span class="o">=</span> <span class="n">file_name</span><span class="p">,</span> <span class="n">path</span> <span class="o">=</span> <span class="n">path_input</span><span class="p">,</span> <span class="n">pathOut</span> <span class="o">=</span> <span class="n">path_out</span><span class="p">,</span>
          <span class="n">areaFilter</span> <span class="o">=</span> <span class="mi">1500</span><span class="p">,</span> <span class="n">thr</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
<p>The CNNDeploy function returns a binary mask of the cells that represent the chosen phenotype. This mask is saved as binary.tif and then uploaded to the NIS-Elements module, where it is converted into a Region of Interest (ROI). The simulation module then takes the photostimulation raster and uses a UV laser to activate those regions.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</section>
<section id="enrichment-analysis-crisper-i-screen">
<h2>7 Enrichment Analysis  - Crisper[i] Screen<a class="headerlink" href="#enrichment-analysis-crisper-i-screen" title="Permalink to this headline"></a></h2>
<p>Our platform allows for screening rates of up to one million cells per run, with a minimum rate of 100,000 cells. To optimize this process, an enrichment strategy has been developed.</p>
<p>In a CRISPR perturbation screen, the Geometric Distribution is the most commonly used sgRNA sequencing distribution, with an emphasis on evenly distributes sgRNAs across a gene or set of genes. However, the Negative Binomial Distribution is also used and provides more accurate measurement of perturbation by emphasizing the number of times a gene target is hit.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">Simulate</span></code> module simulates AIPS by definingthe  the sgRNA pool for a given gene using the <code class="docutils literal notranslate"><span class="pre">lookupString</span></code> parameter. It uses the published crispri sgRNA data (Horlbeck et al) and a Negative Binomial distribution with parameters n and p to determine the number of effective (successful) sgRNA in the pool , as shown in the Python library <a class="reference external" href="https://www.pymc.io/welcome.html">pymc</a>. The argument <code class="docutils literal notranslate"><span class="pre">tpRatio</span></code> indicates the number of effective target sgRNA in the pool. It is known that approximately 0.2 to 0.4 of the sgRNA targeting a particular gene are effective, according to the paper by Daley et al.</p>
<ul class="simple">
<li><p>Max A Horlbeck, Luke A Gilbert, Jacqueline E Villalta, Britt Adamson, Ryan A Pak, Yuwen Chen, Alexander P Fields, Chong Yon Park, Jacob E Corn, Martin Kampmann, Jonathan S Weissman (2016) Compact and highly active next-generation libraries for CRISPR-mediated gene repression and activation eLife 5:e19760 https://doi.org/10.7554/eLife.19760</p></li>
<li><p>Daley, T., Lin, Z., Lin, X. et al. CRISPhieRmix: a hierarchical mixture model for CRISPR pooled screens. Genome Biol 19, 159 (2018). https://doi.org/10.1186/s13059-018-1538-6</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">AIPyS</span> <span class="kn">import</span> <span class="n">AIPS_simulate</span> <span class="k">as</span> <span class="n">sim</span>
<span class="c1"># filtered list of sgRNA data from the reference library for the sub library h4</span>
<span class="n">dfH4</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;dfH4.csv&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>The command <code class="docutils literal notranslate"><span class="pre">simulation</span></code> defines the false positives limits and the number of observations per acquisition, which is drawn from a normal distribution.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">orig</span><span class="p">,</span> <span class="n">Q1</span><span class="p">,</span> <span class="n">Q2</span> <span class="o">=</span> <span class="n">sim</span><span class="o">.</span><span class="n">Simulate</span><span class="p">(</span><span class="n">df</span> <span class="o">=</span> <span class="n">dfH4</span> <span class="p">,</span><span class="n">lookupString</span> <span class="o">=</span>  <span class="s1">&#39;PEX&#39;</span> <span class="p">,</span><span class="n">tpRatio</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span> <span class="mi">10</span> <span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">)</span><span class="o">.</span><span class="n">simulation</span><span class="p">(</span>
                            <span class="n">FalseLimits</span>  <span class="o">=</span> <span class="p">(</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.5</span><span class="p">),</span> <span class="n">ObservationNum</span> <span class="o">=</span> <span class="p">(</span><span class="mi">70</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span>
</pre></div>
</div>
<p>This function returns three data frames: <code class="docutils literal notranslate"><span class="pre">orig</span></code> contains the original read counts, <code class="docutils literal notranslate"><span class="pre">Q1</span></code> contains the read counts of the sgRNAs not selected during acquisition, and <code class="docutils literal notranslate"><span class="pre">Q2</span></code> contains the read counts of the selected hits the “activated” sample.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;activeSg&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">indexPexActiveArray</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">indexTarget</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tpRatio</span><span class="p">)]</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">indexPexActiveArray</span><span class="p">,</span> <span class="s1">&#39;activeSg&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
<span class="c1"># list of sgRNA which are true</span>
<span class="n">TruePositiveSGs</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">indexPexActiveArray</span><span class="p">,</span> <span class="s1">&#39;sgID&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to_list</span><span class="p">())</span>
</pre></div>
</div>
<p>Enrichment analysis was performed by comparing the activated simulated data (Q2) with the non-activated simulated data (Q1). Mapping of the read counts was done according to the unique Gene names, and the perturbation effects were calculated by dividing the log count data of Q2 by that of Q1.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">AIPyS</span> <span class="kn">import</span> <span class="n">mapSgRNA</span>
<span class="c1"># filtered list of sgRNA data from the reference library for the sub library h4</span>
<span class="n">pathIn</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">&#39;F:\HAB_2\PrinzScreen\AIPS_simulation\AIPS_simulation\data&#39;</span>
<span class="n">Q2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pathIn</span><span class="p">,</span><span class="s1">&#39;h4_1_45tpGuide_Q2.csv&#39;</span><span class="p">))</span>
<span class="n">Q1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pathIn</span><span class="p">,</span><span class="s1">&#39;h4_1_45tpGuide_Q1.csv&#39;</span><span class="p">))</span>
<span class="c1"># unique</span>

<span class="n">uniqueSgRNA</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">Q2</span><span class="o">.</span><span class="n">sgID</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

<span class="c1"># The mapping of unique sgRNA to the SIM was performed using the module mapsgrna</span>

<span class="n">dictDF</span> <span class="o">=</span> <span class="n">mapSgRNA</span><span class="p">(</span><span class="n">df1</span> <span class="o">=</span> <span class="n">Q1</span><span class="p">,</span> <span class="n">df2</span> <span class="o">=</span> <span class="n">Q2</span><span class="p">)</span>

<span class="c1"># Make dictionary mapping reads to unique sgRNA</span>

<span class="n">df_dict</span> <span class="o">=</span> <span class="n">dictDF</span><span class="o">.</span><span class="n">mapping</span><span class="p">(</span><span class="n">uniqueSgRNA</span> <span class="o">=</span> <span class="n">uniqueSgRNA</span><span class="p">)</span>

<span class="c1"># data frame contain logFC and z-score logFC</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">dictDF</span><span class="o">.</span><span class="n">dataFrameFinal</span><span class="p">(</span><span class="n">df_dict</span><span class="p">)</span>
</pre></div>
</div>
<center><b><u>Simulation</u></b></center>
<p><img alt="png" src="_images/output_7_0_0.png" /></p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="install/index.html" class="btn btn-neutral float-left" title="Installing AIPyS" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="API.html" class="btn btn-neutral float-right" title="AIPyS modules" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Gil Kanfer, PhD.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>