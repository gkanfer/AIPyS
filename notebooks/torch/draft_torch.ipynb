{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db1ad17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available(), torch.cuda.device_count())\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "device = torch.device(\"cuda\")\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "480763db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 60, 60]) 0\n",
      "Follwing classes are there : \n",
      " ['PEX', 'WT']\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/data/kanferg/Images/Pex_project/SIngle_cell_images_training_set/01242024/pytorch_test/seg_train/'\n",
    "test_data_dir = '/data/kanferg/Images/Pex_project/SIngle_cell_images_training_set/01242024/pytorch_test/seg_test/'\n",
    "\n",
    "dataset = ImageFolder(data_dir,transform = transforms.Compose([\n",
    "    transforms.Resize((60,60)),transforms.ColorJitter(),transforms.ToTensor(),transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "]))\n",
    "test_dataset = ImageFolder(test_data_dir,transforms.Compose([\n",
    "    transforms.Resize((60,60)),transforms.ColorJitter(),transforms.ToTensor(),transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "]))\n",
    "\n",
    "img, label = dataset[0]\n",
    "\n",
    "print(img.shape,label) \n",
    "print(\"Follwing classes are there : \\n\",dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50ed8a70-987e-4187-89ae-a0028d4cd7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label : PEX\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display_img(img,label):\n",
    "    print(f\"Label : {dataset.classes[label]}\")\n",
    "    plt.imshow(img.permute(1,2,0))\n",
    "'''\n",
    "In the function `img.permute(1,2,0)`, `permute(1,2,0)` is used to change the dimensions of the `img` object.\n",
    "\n",
    "The `img` object has dimensions `torch.Size([3, 150, 150])`, which means it has 3 channels (RGB) and an image size of 150x150 pixels.\n",
    "'''\n",
    "#display the first image in the dataset\n",
    "display_img(*dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fbf489b-0e70-486c-a663-9236077a6aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2348, -0.1487,  0.0953,  ..., -0.3404, -0.3404, -0.3404],\n",
       "        [ 0.2173,  0.0082,  0.1302,  ..., -0.3404, -0.3404, -0.3404],\n",
       "        [ 0.1476, -0.0790,  0.1651,  ..., -0.3404, -0.3404, -0.3404],\n",
       "        ...,\n",
       "        [-0.3404, -0.3404, -0.3404,  ...,  0.3568,  0.4788,  0.5136],\n",
       "        [-0.3404, -0.3404, -0.3404,  ...,  0.4962,  0.4962,  0.5834],\n",
       "        [-0.3404, -0.3404, -0.3404,  ...,  0.4788,  0.5311,  0.5485]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[2,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54d4dae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Train Data : 14000\n",
      "Length of Validation Data : 1000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "val_size = 1000\n",
    "train_size = len(dataset) - val_size \n",
    "\n",
    "train_data,val_data = random_split(dataset,[train_size,val_size])\n",
    "print(f\"Length of Train Data : {len(train_data)}\")\n",
    "print(f\"Length of Validation Data : {len(val_data)}\")\n",
    "\n",
    "#output\n",
    "#Length of Train Data : 15000*0.8\n",
    "#Length of Validation Data : 15000*0.2\n",
    "\n",
    "#load the train and validation into batches.\n",
    "# train_dl = DataLoader(train_data, batch_size, shuffle = True, num_workers = 4, pin_memory = True)\n",
    "# val_dl = DataLoader(val_data, batch_size, num_workers = 4, pin_memory = True)\n",
    "train_dl = DataLoader(train_data, batch_size, shuffle = True, pin_memory = True)\n",
    "val_dl = DataLoader(val_data, batch_size, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffd2a470",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassificationBase(nn.Module):\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        labels = labels.view(-1, 1)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = criterion(out, labels.float()) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        out = self(images)                    # Generate predictions\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        labels = labels.view(-1, 1)\n",
    "        loss = criterion(out, labels.float())  # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd9d5d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaturalSceneClassification(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(3, 16, kernel_size = 3),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(16,64, kernel_size = 3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "        \n",
    "            nn.Conv2d(64, 128, kernel_size = 3),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(128 ,128, kernel_size = 3),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1*1*128, 512), #incase of 60 by 60 input image\n",
    "            #nn.Linear(7*7*128, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25e8bc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    preds = outputs > 0.5\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "  \n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "  \n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n",
    "    \n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(),lr)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for i,batch in enumerate(train_loader):\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # if i % 10 == 0:\n",
    "            #     result = evaluate(model, val_loader)\n",
    "            #     result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "            #     model.epoch_end(epoch, result)\n",
    "        \n",
    "        print(epoch)\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ebb7459",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaturalSceneClassification().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d92dfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, data in enumerate(train_dl, 0):\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    inputs, labels = data\n",
    "    if i  == 0:\n",
    "        break\n",
    "imgTest = inputs[0,:,:,:]\n",
    "plt.imshow(imgTest.permute(1,2,0))\n",
    "plt.title(labels[0])\n",
    "plt.show()\n",
    "inputs,labels = inputs.to(device),labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fd66521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b708235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_tensor = torch.randn(30, 3, 50, 50)\n",
    "# optimizer= torch.optim.SGD(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d19cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(inputs)\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "# labels = labels.view(-1, 1)\n",
    "# loss = criterion(model(inputs), labels.float())\n",
    "# optimizer.zero_grad()\n",
    "# loss.backward()\n",
    "# optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3b4a950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0.post303\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8563b963",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gsfs10/users/kanferg/conda/envs/cellpose_utsw/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /home/conda/feedstock_root/build_artifacts/libtorch_1705951072540/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], train_loss: 0.6019, val_loss: 0.7158, val_acc: 0.4840\n",
      "Epoch [0], train_loss: 0.7236, val_loss: 0.7147, val_acc: 0.4840\n",
      "Epoch [0], train_loss: 0.7173, val_loss: 0.7140, val_acc: 0.4840\n",
      "Epoch [0], train_loss: 0.7187, val_loss: 0.7131, val_acc: 0.4840\n",
      "Epoch [0], train_loss: 0.7162, val_loss: 0.7124, val_acc: 0.4840\n",
      "Epoch [0], train_loss: 0.7146, val_loss: 0.7116, val_acc: 0.4840\n",
      "Epoch [0], train_loss: 0.7210, val_loss: 0.7102, val_acc: 0.4840\n",
      "Epoch [0], train_loss: 0.7220, val_loss: 0.7091, val_acc: 0.4840\n",
      "Epoch [0], train_loss: 0.7200, val_loss: 0.7082, val_acc: 0.4840\n",
      "Epoch [0], train_loss: 0.7146, val_loss: 0.7078, val_acc: 0.4840\n",
      "Epoch [0], train_loss: 0.7135, val_loss: 0.7067, val_acc: 0.4840\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# fitting the model on training data and record the result after each epoch\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#torch.save(model.state_dict(), \"model_test.pth\")\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 27\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(epochs, lr, model, train_loader, val_loader, opt_func)\u001b[0m\n\u001b[1;32m     25\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 27\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(train_losses)\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     29\u001b[0m     model\u001b[38;5;241m.\u001b[39mepoch_end(epoch, result)\n",
      "File \u001b[0;32m/gpfs/gsfs10/users/kanferg/conda/envs/cellpose_utsw/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, val_loader)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(model, val_loader):\n\u001b[1;32m      8\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m----> 9\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mvalidation_epoch_end(outputs)\n",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(model, val_loader):\n\u001b[1;32m      8\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m----> 9\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mvalidation_epoch_end(outputs)\n",
      "File \u001b[0;32m/gpfs/gsfs10/users/kanferg/conda/envs/cellpose_utsw/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/gpfs/gsfs10/users/kanferg/conda/envs/cellpose_utsw/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/gpfs/gsfs10/users/kanferg/conda/envs/cellpose_utsw/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m/gpfs/gsfs10/users/kanferg/conda/envs/cellpose_utsw/lib/python3.11/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/gpfs/gsfs10/users/kanferg/conda/envs/cellpose_utsw/lib/python3.11/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m/gpfs/gsfs10/users/kanferg/conda/envs/cellpose_utsw/lib/python3.11/site-packages/torchvision/datasets/folder.py:229\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03m    index (int): Index\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m    tuple: (sample, target) where target is class_index of the target class.\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m path, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples[index]\n\u001b[0;32m--> 229\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(sample)\n",
      "File \u001b[0;32m/gpfs/gsfs10/users/kanferg/conda/envs/cellpose_utsw/lib/python3.11/site-packages/torchvision/datasets/folder.py:268\u001b[0m, in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accimage_loader(path)\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpil_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/gpfs/gsfs10/users/kanferg/conda/envs/cellpose_utsw/lib/python3.11/site-packages/torchvision/datasets/folder.py:247\u001b[0m, in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpil_loader\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Image\u001b[38;5;241m.\u001b[39mImage:\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 247\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/gpfs/gsfs10/users/kanferg/conda/envs/cellpose_utsw/lib/python3.11/site-packages/PIL/Image.py:3256\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3253\u001b[0m     fp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(fp\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m   3254\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 3256\u001b[0m prefix \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m   3258\u001b[0m preinit()\n\u001b[1;32m   3260\u001b[0m accept_warnings \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "# opt_func = torch.optim.Adam\n",
    "opt_func= torch.optim.SGD\n",
    "lr = 0.05\n",
    "# fitting the model on training data and record the result after each epoch\n",
    "history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)\n",
    "#torch.save(model.state_dict(), \"model_test.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baadd59-8264-451e-ba8b-00e096a8426b",
   "metadata": {},
   "source": [
    "tensor([[1],\n",
    "        [0],\n",
    "        [0],\n",
    "        [0]], device='cuda:0')\n",
    "\n",
    "tensor([[0.5050],\n",
    "        [0.5042],\n",
    "        [0.5044],\n",
    "        [0.5046]], device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83c1c9f2-96fe-49e5-99e9-38179ca62401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.tensor([[0.5050],[0.5042],[0.5044],[0.5046]])\n",
    "label = torch.tensor([[1],[0],[0],[0]])\n",
    "\n",
    "_, preds = torch.max(out, dim=0)\n",
    "torch.tensor(torch.sum(preds == label).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "98822b45-0759-4935-88de-b9d8edc5494e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2500)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.tensor([[0.5050],[0.5042],[0.5044],[0.5046]])\n",
    "label = torch.tensor([[1],[0],[0],[0]])\n",
    "\n",
    "preds = out > 0.5\n",
    "torch.tensor(torch.sum(preds == label).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d477f29f-c987-4c8f-b66f-09b3de043085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5049],\n",
       "        [0.5048],\n",
       "        [0.5051],\n",
       "        [0.5055],\n",
       "        [0.5049],\n",
       "        [0.5048],\n",
       "        [0.5045],\n",
       "        [0.5049],\n",
       "        [0.5054],\n",
       "        [0.5051],\n",
       "        [0.5043],\n",
       "        [0.5052],\n",
       "        [0.5054],\n",
       "        [0.5052],\n",
       "        [0.5050],\n",
       "        [0.5050],\n",
       "        [0.5048],\n",
       "        [0.5051],\n",
       "        [0.5052],\n",
       "        [0.5046],\n",
       "        [0.5052],\n",
       "        [0.5047],\n",
       "        [0.5050],\n",
       "        [0.5043],\n",
       "        [0.5046],\n",
       "        [0.5053],\n",
       "        [0.5049],\n",
       "        [0.5044],\n",
       "        [0.5046],\n",
       "        [0.5050]], device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randn(30, 3, 50, 50).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe78be1e-3f23-46dc-be88-a9de69cf1d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.662051  [    0/14000]\n",
      "loss: 0.782744  [ 1600/14000]\n",
      "loss: 0.691786  [ 3200/14000]\n",
      "loss: 0.751883  [ 4800/14000]\n",
      "loss: 0.691496  [ 6400/14000]\n",
      "loss: 0.661097  [ 8000/14000]\n",
      "loss: 0.751212  [ 9600/14000]\n",
      "loss: 0.779935  [11200/14000]\n",
      "loss: 0.720527  [12800/14000]\n",
      "loss: 0.631215  [    0/14000]\n",
      "loss: 0.690133  [ 1600/14000]\n",
      "loss: 0.660823  [ 3200/14000]\n",
      "loss: 0.660905  [ 4800/14000]\n",
      "loss: 0.777120  [ 6400/14000]\n",
      "loss: 0.660817  [ 8000/14000]\n",
      "loss: 0.689434  [ 9600/14000]\n",
      "loss: 0.631910  [11200/14000]\n",
      "loss: 0.660414  [12800/14000]\n",
      "loss: 0.659996  [    0/14000]\n",
      "loss: 0.746385  [ 1600/14000]\n",
      "loss: 0.717768  [ 3200/14000]\n",
      "loss: 0.660177  [ 4800/14000]\n",
      "loss: 0.744499  [ 6400/14000]\n",
      "loss: 0.659508  [ 8000/14000]\n",
      "loss: 0.714186  [ 9600/14000]\n",
      "loss: 0.770315  [11200/14000]\n",
      "loss: 0.714481  [12800/14000]\n",
      "loss: 0.658938  [    0/14000]\n",
      "loss: 0.713179  [ 1600/14000]\n",
      "loss: 0.631369  [ 3200/14000]\n",
      "loss: 0.819395  [ 4800/14000]\n",
      "loss: 0.738375  [ 6400/14000]\n",
      "loss: 0.605376  [ 8000/14000]\n",
      "loss: 0.708734  [ 9600/14000]\n",
      "loss: 0.790087  [11200/14000]\n",
      "loss: 0.758458  [12800/14000]\n",
      "loss: 0.706032  [    0/14000]\n",
      "loss: 0.676903  [ 1600/14000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# fitting the model on training data and record the result after each epoch\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#torch.save(model.state_dict(), \"model_test.pth\")\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[24], line 10\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(epochs, lr, model, train_loader, val_loader, opt_func)\u001b[0m\n\u001b[1;32m      8\u001b[0m train_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[0;32m---> 10\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_losses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/gpfs/gsfs10/users/kanferg/conda/envs/cellpose_utsw/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/gpfs/gsfs10/users/kanferg/conda/envs/cellpose_utsw/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/gpfs/gsfs10/users/kanferg/conda/envs/cellpose_utsw/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m/gpfs/gsfs10/users/kanferg/conda/envs/cellpose_utsw/lib/python3.11/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/gpfs/gsfs10/users/kanferg/conda/envs/cellpose_utsw/lib/python3.11/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m/gpfs/gsfs10/users/kanferg/conda/envs/cellpose_utsw/lib/python3.11/site-packages/torchvision/datasets/folder.py:229\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03m    index (int): Index\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m    tuple: (sample, target) where target is class_index of the target class.\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m path, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples[index]\n\u001b[0;32m--> 229\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(sample)\n",
      "File \u001b[0;32m/gpfs/gsfs10/users/kanferg/conda/envs/cellpose_utsw/lib/python3.11/site-packages/torchvision/datasets/folder.py:268\u001b[0m, in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accimage_loader(path)\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpil_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/gpfs/gsfs10/users/kanferg/conda/envs/cellpose_utsw/lib/python3.11/site-packages/torchvision/datasets/folder.py:247\u001b[0m, in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpil_loader\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Image\u001b[38;5;241m.\u001b[39mImage:\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 247\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/gpfs/gsfs10/users/kanferg/conda/envs/cellpose_utsw/lib/python3.11/site-packages/PIL/Image.py:3256\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3253\u001b[0m     fp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(fp\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m   3254\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 3256\u001b[0m prefix \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m   3258\u001b[0m preinit()\n\u001b[1;32m   3260\u001b[0m accept_warnings \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# change fit function acording to https://www.kaggle.com/code/abhishekrathi09/pytorch-basics-part-4-optimize-model-parameters\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n",
    "    \n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(),lr)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        size = len(train_loader.dataset)\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                images, labels = batch\n",
    "                loss, current = loss.item(), i * len(images)\n",
    "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        # result = evaluate(model, val_loader)\n",
    "        # result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        # model.epoch_end(epoch, result)\n",
    "        # history.append(result)\n",
    "    \n",
    "    return history\n",
    "\n",
    "num_epochs = 30\n",
    "# opt_func = torch.optim.Adam\n",
    "opt_func= torch.optim.SGD\n",
    "lr = 0.001\n",
    "# fitting the model on training data and record the result after each epoch\n",
    "history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)\n",
    "#torch.save(model.state_dict(), \"model_test.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86d1034-6289-4d5b-99ee-d89a38ad6640",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
